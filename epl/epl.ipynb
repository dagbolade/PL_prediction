{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Premier League 2023/24 predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baffb21ee741de4f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e632784a4a65bae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the excel file\n",
    "#file_path = 'all-euro-data-2023-2024.xlsx'\n",
    "#df = pd.read_excel(file_path, sheet_name='E0')\n",
    "\n",
    "# updating the dataset with the recent games played\n",
    "df = pd.read_csv('E0.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.tail()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79b87f51e58715a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10f8ed427cf2825e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5f7fe372ecbbe43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# steps:\n",
    "# 1. Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# 2. Check for duplicates\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "# Display the results of the checks\n",
    "missing_values, duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dropping columns with a high number of missing values or irrelevant to our analysis\n",
    "irrelevant_columns = df.columns[df.isnull().sum() > (0.5 * len(df))]  # Columns with more than 50% missing values\n",
    "df_cleaned = df.drop(columns=irrelevant_columns)\n",
    "\n",
    "# Convert 'Date' to datetime\n",
    "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Fill missing values in other relevant columns with appropriate values (like median or mode)\n",
    "# For numerical columns, we use median and for categorical, we use mode\n",
    "for column in df_cleaned.columns:\n",
    "    if df_cleaned[column].dtype == 'object':\n",
    "        df_cleaned[column].fillna(df_cleaned[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df_cleaned[column].fillna(df_cleaned[column].median(), inplace=True)\n",
    "\n",
    "# Recheck for missing values\n",
    "remaining_missing_values = df_cleaned.isnull().sum().sum()\n",
    "\n",
    "# Basic information after cleaning\n",
    "remaining_missing_values, df_cleaned.info()\n",
    "\n",
    "df_cleaned.head()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cb7cecf0d962cfc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert df_cleaned to csv\n",
    "\n",
    "df_cleaned.to_csv('E0_cleaned.csv', index=False)\n",
    "\n",
    "# load the cleaned dataset\n",
    "\n",
    "df_cleaned = pd.read_csv('E0_cleaned.csv')\n",
    "\n",
    "df_cleaned.head()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f229a0b091e42f7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature engineering\n",
    "\n",
    "### steps:\n",
    "* Encode Team Names: Use label encoding for 'HomeTeam' and 'AwayTeam'. This will convert team names into numeric values, making them usable for the model.\n",
    "\n",
    "* Recent Form: Calculate the recent form for each team based on the last 5 matches. We'll use the 'FTR' column to determine wins (W), losses (L), and draws (D). This feature will provide insight into the current performance of the teams.\n",
    "\n",
    "* Average Goals per Game: Compute the average goals scored per game for both home and away teams. This feature helps understand the offensive strength of the teams.\n",
    "\n",
    "* Team Points: Calculate the total points accumulated by each team so far in the season. Points are awarded based on wins (3 points), draws (1 point), and losses (0 points).\n",
    "\n",
    "* Head-to-Head Statistics: Analyze the outcomes of matches between the same pairs of teams earlier in the season.\n",
    "\n",
    "* Other Statistical Features: Depending on the data available, we can include additional features like average possession, number of shots on target, defensive strength, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42e90ef27df5a84d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode team names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90a4cf9baa0697fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the LabelEncoder class from the sklearn library\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the team names\n",
    "label_encoder = LabelEncoder()\n",
    "df_cleaned['HomeTeamEncoded'] = label_encoder.fit_transform(df_cleaned['HomeTeam'])\n",
    "df_cleaned['AwayTeamEncoded'] = label_encoder.transform(df_cleaned['AwayTeam'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41e159a547fd0959"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recent form"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ca09767512e1ab4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# function to calculate recent form\n",
    "def calculate_form_points(team, df_cleaned, num_matches=5):\n",
    "    # Filter the matches for the team\n",
    "    team_matches = df_cleaned[(df_cleaned['HomeTeam'] == team) | (df_cleaned['AwayTeam'] == team)]\n",
    "    # Sort by date to get the most recent matches\n",
    "    team_matches = team_matches.sort_values(by='Date', ascending=False)\n",
    "    # Get the last 'num_matches' matches\n",
    "    recent_matches = team_matches.head(num_matches)\n",
    "    # Calculate form points\n",
    "    form_points = 0\n",
    "    for _, row in recent_matches.iterrows():\n",
    "        if row['HomeTeam'] == team and row['FTR'] == 'H':\n",
    "            form_points += 3\n",
    "        elif row['AwayTeam'] == team and row['FTR'] == 'A':\n",
    "            form_points += 3\n",
    "        elif row['FTR'] == 'D':\n",
    "            form_points += 1\n",
    "    return form_points\n",
    "\n",
    "# Apply the function to get recent form for each team in each match\n",
    "df_cleaned['HomeTeamRecentForm'] = df_cleaned.apply(lambda x: calculate_form_points(x['HomeTeam'], df_cleaned), axis=1)\n",
    "df_cleaned['AwayTeamRecentForm'] = df_cleaned.apply(lambda x: calculate_form_points(x['AwayTeam'], df_cleaned), axis=1)\n",
    "\n",
    "# Average Goals per Game\n",
    "df_cleaned['HomeTeamAvgGoals'] = df_cleaned.groupby('HomeTeam')['FTHG'].transform('mean')\n",
    "df_cleaned['AwayTeamAvgGoals'] = df_cleaned.groupby('AwayTeam')['FTAG'].transform('mean')\n",
    "\n",
    "# half time average goals\n",
    "df_cleaned['HomeTeamAvgGoalsHT'] = df_cleaned.groupby('HomeTeam')['HTHG'].transform('mean')\n",
    "df_cleaned['AwayTeamAvgGoalsHT'] = df_cleaned.groupby('AwayTeam')['HTAG'].transform('mean')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81e5da0ff5d5dfdc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Team Points"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6924b8357152763"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Points will be calculated similar to form but for the whole season\n",
    "def calculate_team_points(team, df_cleaned):\n",
    "    team_matches = df_cleaned[(df_cleaned['HomeTeam'] == team) | (df_cleaned['AwayTeam'] == team)]\n",
    "    points = 0\n",
    "    for _, row in team_matches.iterrows():\n",
    "        if row['HomeTeam'] == team and row['FTR'] == 'H':\n",
    "            points += 3\n",
    "        elif row['AwayTeam'] == team and row['FTR'] == 'A':\n",
    "            points += 3\n",
    "        elif row['FTR'] == 'D':\n",
    "            points += 1\n",
    "    return points\n",
    "\n",
    "df_cleaned['HomeTeamPoints'] = df_cleaned.apply(lambda x: calculate_team_points(x['HomeTeam'], df_cleaned), axis=1)\n",
    "df_cleaned['AwayTeamPoints'] = df_cleaned.apply(lambda x: calculate_team_points(x['AwayTeam'], df_cleaned), axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45b0f7be38c83d77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Head-to-Head Statistics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2b4ebfc5a1ba710"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Head-to-Head Statistics\n",
    "# For simplicity, we can count the number of wins, draws, and losses in matches between the same teams\n",
    "# Note: This implementation is simplified for demonstration purposes\n",
    "def head_to_head_stats(home_team, away_team, df_cleaned):\n",
    "    head_to_head_matches = df_cleaned[(df_cleaned['HomeTeam'] == home_team) & (df['AwayTeam'] == away_team)]\n",
    "    wins = len(head_to_head_matches[head_to_head_matches['FTR'] == 'H'])\n",
    "    draws = len(head_to_head_matches[head_to_head_matches['FTR'] == 'D'])\n",
    "    losses = len(head_to_head_matches[head_to_head_matches['FTR'] == 'A'])\n",
    "    return wins, draws, losses\n",
    "\n",
    "# Apply the head-to-head stats function\n",
    "df_cleaned['HeadToHeadWins'], df_cleaned['HeadToHeadDraws'], df_cleaned['HeadToHeadLosses'] = zip(*df_cleaned.apply(lambda x: head_to_head_stats(x['HomeTeam'], x['AwayTeam'], df_cleaned), axis=1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4a486ca2eadd77f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate Home Team Win Percentage\n",
    "home_team_wins = df_cleaned[df_cleaned['FTR'] == 'H'].groupby('HomeTeam').size()\n",
    "total_home_matches = df_cleaned.groupby('HomeTeam').size()\n",
    "home_team_win_percentage = home_team_wins / total_home_matches\n",
    "# \n",
    "# Calculate Away Team Win Percentage\n",
    "away_team_wins = df_cleaned[df_cleaned['FTR'] == 'A'].groupby('AwayTeam').size()\n",
    "total_away_matches = df_cleaned.groupby('AwayTeam').size()\n",
    "away_team_win_percentage = away_team_wins / total_away_matches\n",
    "# \n",
    "# Create mappings for win percentages\n",
    "home_team_win_percentage_map = home_team_win_percentage.to_dict()\n",
    "away_team_win_percentage_map = away_team_win_percentage.to_dict()\n",
    "# \n",
    "# Map the win percentages to the original DataFrame\n",
    "df_cleaned['HomeTeamWinPercentage'] = df_cleaned['HomeTeam'].map(home_team_win_percentage_map).fillna(0)\n",
    "df_cleaned['AwayTeamWinPercentage'] = df_cleaned['AwayTeam'].map(away_team_win_percentage_map).fillna(0)\n",
    "\n",
    "# calculate the average shots on target for home and away teams\n",
    "df_cleaned['HomeTeamAvgShotsOnTarget'] = df_cleaned.groupby('HomeTeam')['HST'].transform('mean')\n",
    "df_cleaned['AwayTeamAvgShotsOnTarget'] = df_cleaned.groupby('AwayTeam')['AST'].transform('mean')\n",
    "\n",
    " \n",
    "# Check the first few rows to confirm the new features\n",
    "print(df_cleaned[['HomeTeam', 'HomeTeamWinPercentage', 'AwayTeam', 'AwayTeamWinPercentage','HomeTeamAvgShotsOnTarget','AwayTeamAvgShotsOnTarget', 'HomeTeamAvgGoalsHT', 'AwayTeamAvgGoalsHT']].head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2232605c57a1431a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3515a8783f129764"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the current position and calculate points for chelsea and the rest of the teams\n",
    "def calculate_points_goals(row):\n",
    "    home_points, away_points = 0, 0\n",
    "    home_goal_diff = row['FTHG'] - row['FTAG']\n",
    "    away_goal_diff = row['FTAG'] - row['FTHG']\n",
    "\n",
    "    if row['FTR'] == 'H':\n",
    "        home_points = 3\n",
    "    elif row['FTR'] == 'A':\n",
    "        away_points = 3\n",
    "    else:\n",
    "        home_points = away_points = 1\n",
    "\n",
    "    return pd.Series([home_points, away_points, home_goal_diff, away_goal_diff, row['FTHG'], row['FTAG']])\n",
    "\n",
    "# List of teams\n",
    "teams = df_cleaned['HomeTeam'].unique()\n",
    "\n",
    "# Applying the function to the dataset\n",
    "df_cleaned[['HomePoints', 'AwayPoints', 'HomeGoalDiff', 'AwayGoalDiff', 'HomeGoals', 'AwayGoals']] = df_cleaned.apply(calculate_points_goals, axis=1)\n",
    "\n",
    "# Summarizing the data for each team\n",
    "team_stats = pd.DataFrame(index=teams)\n",
    "\n",
    "# Calculating total points, goal difference, and goals scored for each team\n",
    "team_stats['Points'] = df_cleaned.groupby('HomeTeam')['HomePoints'].sum() + df_cleaned.groupby('AwayTeam')['AwayPoints'].sum()\n",
    "team_stats['GoalDiff'] = df_cleaned.groupby('HomeTeam')['HomeGoalDiff'].sum() + df_cleaned.groupby('AwayTeam')['AwayGoalDiff'].sum()\n",
    "team_stats['GoalsScored'] = df_cleaned.groupby('HomeTeam')['HomeGoals'].sum() + df_cleaned.groupby('AwayTeam')['AwayGoals'].sum()\n",
    "\n",
    "# Deducting 10 points from Everton for misconduct\n",
    "team_stats.loc['Everton', 'Points'] = team_stats.loc['Everton', 'Points'] - 10\n",
    "\n",
    "# Sorting the teams based on Points, Goal Difference, and Goals Scored\n",
    "sorted_teams = team_stats.sort_values(by=['Points', 'GoalDiff', 'GoalsScored'], ascending=[False, False, False])\n",
    "\n",
    "# Finding Chelsea's position\n",
    "chelsea_position_updated = sorted_teams.index.get_loc('Chelsea') + 1\n",
    "print('Chelsea is currently in position:', chelsea_position_updated)\n",
    "sorted_teams.head(20), chelsea_position_updated\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50d21ab026b0e87a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing\n",
    "### steps:\n",
    "* Scaling Numeric Features: We'll scale features like recent form, average goals, and points using StandardScaler.\n",
    "* Handling Categorical Variables: We have already encoded team names. We'll ensure other categorical features, if any, are properly encoded.\n",
    "* Splitting the Data: We'll split the data into training and test sets. We'll use the training set to train the model and the test set to evaluate the model's performance on unseen data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "935ae9aec680a4b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# select relevant columns or features\n",
    "features = ['HomeTeamEncoded', 'AwayTeamEncoded', 'HomeTeamRecentForm', 'AwayTeamRecentForm', 'HomeTeamAvgGoals', 'AwayTeamAvgGoals', 'HomeTeamPoints', 'AwayTeamPoints', 'HomeTeamWinPercentage', 'AwayTeamWinPercentage', 'HomeTeamAvgShotsOnTarget', 'AwayTeamAvgShotsOnTarget', 'HomeTeamAvgGoalsHT', 'AwayTeamAvgGoalsHT']\n",
    "target = 'FTR'\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df_cleaned[features]\n",
    "y = df_cleaned[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Addressing Class Imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb111238645ec9fd"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c5390d45d2a87efc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7321b3b954c0744"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "# Define the hyperparameter space\n",
    "space = {\n",
    "    'iterations': hp.quniform('iterations', 100, 1000, 50),\n",
    "    'depth': hp.choice('depth', np.arange(3, 11, dtype=int)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 1, 10),\n",
    "    'bagging_temperature': hp.uniform('bagging_temperature', 0, 1),\n",
    "    'random_strength': hp.uniform('random_strength', 0, 1)\n",
    "    \n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92b9b0b0d8632992"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the Objective Function so that we can use it in the hyperparameter optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "484517077549ebb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def objective(params):\n",
    "    params['iterations'] = int(params['iterations'])\n",
    "    clf = CatBoostClassifier(**params, loss_function='MultiClass', verbose=False)\n",
    "    score = cross_val_score(clf, X_train_scaled, y_train_smote, scoring='accuracy', cv=StratifiedKFold(10)).mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b9a0a9c6c9ee1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run the hyperparameter optimization\n",
    "from hyperopt import tpe, Trials, fmin\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10, trials=trials)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cb5f76b44edce88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_params = {k: int(v) if k in ['iterations', 'depth'] else v for k, v in best.items()}\n",
    "final_model = CatBoostClassifier(**best_params, loss_function='MultiClass', eval_metric='Accuracy', verbose=False)\n",
    "final_model.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c492c6fc709b27c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check for overfitting\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(final_model, X_train_scaled, y_train_smote, cv=6)\n",
    "\n",
    "# Print the average score\n",
    "print(f\"Average Cross-Validation Score: {cv_scores.mean()}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "469475eb5751fba0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = final_model.get_feature_importance()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, feature_importances)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f536f84532fae061"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make predictions for the 2023/24 season\n",
    "def predict_match(home_team, away_team, final_model, scaler):\n",
    "    # Create a dataframe with the appropriate format\n",
    "    match = pd.DataFrame(columns=['HomeTeamEncoded', 'AwayTeamEncoded', 'HomeTeamRecentForm', 'AwayTeamRecentForm', 'HomeTeamAvgGoals', 'AwayTeamAvgGoals', 'HomeTeamPoints', 'AwayTeamPoints', 'HomeTeamWinPercentage', 'AwayTeamWinPercentage', 'HomeTeamAvgShotsOnTarget', 'AwayTeamAvgShotsOnTarget', 'HomeTeamAvgGoalsHT', 'AwayTeamAvgGoalsHT'])\n",
    "    match.loc[0] = [label_encoder.transform([home_team])[0], label_encoder.transform([away_team])[0], calculate_form_points(home_team, df_cleaned), calculate_form_points(away_team, df_cleaned), df_cleaned[df_cleaned['HomeTeam'] == home_team]['HomeTeamAvgGoals'].values[0], df_cleaned[df_cleaned['AwayTeam'] == away_team]['AwayTeamAvgGoals'].values[0], calculate_team_points(home_team, df_cleaned), calculate_team_points(away_team, df_cleaned), home_team_win_percentage[home_team], away_team_win_percentage[away_team], df_cleaned[df_cleaned['HomeTeam'] == home_team]['HomeTeamAvgShotsOnTarget'].values[0], df_cleaned[df_cleaned['AwayTeam'] == away_team]['AwayTeamAvgShotsOnTarget'].values[0], df_cleaned[df_cleaned['HomeTeam'] == home_team]['HomeTeamAvgGoalsHT'].values[0], df_cleaned[df_cleaned['AwayTeam'] == away_team]['AwayTeamAvgGoalsHT'].values[0]]\n",
    "    # Scale the features\n",
    "    match_scaled = scaler.transform(match)\n",
    "    # Make predictions\n",
    "    home_team_win_prob = final_model.predict_proba(match_scaled)[0][0]\n",
    "    away_team_win_prob = final_model.predict_proba(match_scaled)[0][2]\n",
    "    draw_prob = final_model.predict_proba(match_scaled)[0][1]\n",
    "    # Print the results\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    \n",
    "    return home_team_win_prob, away_team_win_prob, draw_prob\n",
    "\n",
    "# sheffield vs luton\n",
    "predict_match('Chelsea', 'Crystal Palace', final_model, scaler)\n",
    "\n",
    "# Brentforf vs Wolves\n",
    "predict_match('Brentford', 'Wolves', final_model, scaler)\n",
    "\n",
    "\n",
    "# manchester utd vs aston villa\n",
    "predict_match('Everton', 'Man City', final_model, scaler)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "466a379df799b300"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Addressing Class Imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "    \n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1_macro')\n",
    "grid_search.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Best Model Evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18bce7a7c93c20cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check for overfitting\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(best_model, X_train_scaled, y_train_smote, cv=6)\n",
    "\n",
    "# Print the average score\n",
    "print(f\"Average Cross-Validation Score: {cv_scores.mean()}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66a94522869054e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, feature_importances)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "276172cf85bdf498"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make predictions for the 2023/24 season\n",
    "def predict_match(home_team, away_team, best_model, scaler):\n",
    "    # Create a dataframe with the appropriate format\n",
    "    match = pd.DataFrame(columns=['HomeTeamEncoded', 'AwayTeamEncoded', 'HomeTeamRecentForm', 'AwayTeamRecentForm', 'HomeTeamAvgGoals', 'AwayTeamAvgGoals', 'HomeTeamPoints', 'AwayTeamPoints', 'HomeTeamWinPercentage', 'AwayTeamWinPercentage', 'HomeTeamAvgShotsOnTarget', 'AwayTeamAvgShotsOnTarget', 'HomeTeamAvgGoalsHT', 'AwayTeamAvgGoalsHT'])\n",
    "    match.loc[0] = [label_encoder.transform([home_team])[0], label_encoder.transform([away_team])[0], calculate_form_points(home_team, df_cleaned), calculate_form_points(away_team, df_cleaned), df_cleaned[df_cleaned['HomeTeam'] == home_team]['HomeTeamAvgGoals'].values[0], df_cleaned[df_cleaned['AwayTeam'] == away_team]['AwayTeamAvgGoals'].values[0], calculate_team_points(home_team, df_cleaned), calculate_team_points(away_team, df_cleaned), home_team_win_percentage[home_team], away_team_win_percentage[away_team], df_cleaned[df_cleaned['HomeTeam'] == home_team]['HomeTeamAvgShotsOnTarget'].values[0], df_cleaned[df_cleaned['AwayTeam'] == away_team]['AwayTeamAvgShotsOnTarget'].values[0], df_cleaned[df_cleaned['HomeTeam'] == home_team]['HomeTeamAvgGoalsHT'].values[0], df_cleaned[df_cleaned['AwayTeam'] == away_team]['AwayTeamAvgGoalsHT'].values[0]]\n",
    "    # Scale the features\n",
    "    match_scaled = scaler.transform(match)\n",
    "    # Make predictions\n",
    "    home_team_win_prob = best_model.predict_proba(match_scaled)[0][0]\n",
    "    away_team_win_prob = best_model.predict_proba(match_scaled)[0][2]\n",
    "    draw_prob = best_model.predict_proba(match_scaled)[0][1]\n",
    "    # Print the results\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    \n",
    "    return home_team_win_prob, away_team_win_prob, draw_prob\n",
    "\n",
    "\n",
    "# sheffield vs luton\n",
    "predict_match('Chelsea', 'Crystal Palace', best_model, scaler)\n",
    "\n",
    "# Brentforf vs Wolves\n",
    "predict_match('Brentford', 'Wolves', best_model, scaler)\n",
    "\n",
    "\n",
    "# manchester utd vs aston villa\n",
    "predict_match('Everton', 'Man City', best_model, scaler)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "864cf4cbe4d554f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compare the two models\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81fb003a328da524"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# making predictions for total goals in a game\n",
    "\n",
    "#calculate recrent form in terms of goals scored\n",
    "df_cleaned['HomeTeamRecentGoals'] = df_cleaned.groupby('HomeTeam')['FTHG'].rolling(window=5, min_periods=1).sum().reset_index(drop=True)\n",
    "df_cleaned['AwayTeamRecentGoals'] = df_cleaned.groupby('AwayTeam')['FTAG'].rolling(window=5, min_periods=1).sum().reset_index(drop=True)\n",
    "\n",
    "#calculate average goals scored\n",
    "df_cleaned['HomeTeamAvgGoals'] = df_cleaned.groupby('HomeTeam')['FTHG'].transform('mean')\n",
    "df_cleaned['AwayTeamAvgGoals'] = df_cleaned.groupby('AwayTeam')['FTAG'].transform('mean')\n",
    "\n",
    "#calculate average goals conceded\n",
    "df_cleaned['HomeTeamAvgGoalsConceded'] = df_cleaned.groupby('HomeTeam')['FTAG'].transform('mean')\n",
    "df_cleaned['AwayTeamAvgGoalsConceded'] = df_cleaned.groupby('AwayTeam')['FTHG'].transform('mean')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cfb3f7c516a5967"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# select relevant columns or features\n",
    "features = ['HomeTeamEncoded', 'AwayTeamEncoded', 'HomeTeamRecentForm', 'AwayTeamRecentForm', 'HomeTeamAvgGoals', 'AwayTeamAvgGoals', 'HomeTeamPoints', 'AwayTeamPoints', 'HomeTeamWinPercentage', 'AwayTeamWinPercentage', 'HomeTeamAvgShotsOnTarget', 'AwayTeamAvgShotsOnTarget','HomeTeamAvgGoals', 'AwayTeamAvgGoals', 'HomeTeamAvgGoalsConceded', 'AwayTeamAvgGoalsConceded', 'HomeTeamRecentGoals', 'AwayTeamRecentGoals']\n",
    "x = df_cleaned[features]\n",
    "\n",
    "# target variables for total goals in a game\n",
    "y = df_cleaned['FTHG'] + df_cleaned['FTAG']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af0ac0ae56d1d328"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57a970ec8a547059"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predicted_goals = model.predict(X_test_scaled)\n",
    "\n",
    "# determine over/under 1.5 goals\n",
    "over_under_1_5 = ['Over 1.5' if goals > 1.5 else 'Under 1.5' for goals in predicted_goals]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1c6d5bf62098903"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(f\"R2 Score: {r2_score(y_test, predicted_goals)}\")\n",
    "print(f\"RMSE: {mean_squared_error(y_test, predicted_goals, squared=False)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, predicted_goals)}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "777f97fe199573cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "28d0489769e6678c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
