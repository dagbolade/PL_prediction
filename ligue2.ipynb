{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Championship 2023-2024 Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2043b1fe4e1c4d13"
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.045251900Z",
     "start_time": "2024-01-24T00:33:59.827710200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Div        Date   Time        HomeTeam  AwayTeam  FTHG  FTAG FTR  HTHG  \\\n195  F2  13/01/2024  18:00  Quevilly Rouen  Guingamp     0     1   A     0   \n196  F2  13/01/2024  18:00           Rodez    Pau FC     2     1   H     0   \n197  F2  13/01/2024  18:00          Troyes   Ajaccio     3     1   H     1   \n198  F2  13/01/2024  18:00    Valenciennes    Amiens     0     1   A     0   \n199  F2  15/01/2024  19:45         Auxerre  Bordeaux     3     1   H     1   \n\n     HTAG  ... AvgC<2.5  AHCh  B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  \\\n195     0  ...     1.51  0.00      2.05      1.80   2.14   1.78     2.14   \n196     0  ...     2.10 -0.50      1.83      2.03   1.86   2.03     1.90   \n197     1  ...     1.45  0.00      1.98      1.88   1.99   1.90     2.04   \n198     1  ...     1.46  0.25      1.80      2.05   1.81   2.09     1.87   \n199     1  ...     2.09 -0.50      1.93      1.93   1.92   1.97     1.93   \n\n     MaxCAHA  AvgCAHH  AvgCAHA  \n195     1.84     2.03     1.79  \n196     2.07     1.81     1.99  \n197     1.92     1.95     1.86  \n198     2.12     1.77     2.05  \n199     2.15     1.84     1.95  \n\n[5 rows x 105 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>...</th>\n      <th>AvgC&lt;2.5</th>\n      <th>AHCh</th>\n      <th>B365CAHH</th>\n      <th>B365CAHA</th>\n      <th>PCAHH</th>\n      <th>PCAHA</th>\n      <th>MaxCAHH</th>\n      <th>MaxCAHA</th>\n      <th>AvgCAHH</th>\n      <th>AvgCAHA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>F2</td>\n      <td>13/01/2024</td>\n      <td>18:00</td>\n      <td>Quevilly Rouen</td>\n      <td>Guingamp</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.51</td>\n      <td>0.00</td>\n      <td>2.05</td>\n      <td>1.80</td>\n      <td>2.14</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>1.84</td>\n      <td>2.03</td>\n      <td>1.79</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>F2</td>\n      <td>13/01/2024</td>\n      <td>18:00</td>\n      <td>Rodez</td>\n      <td>Pau FC</td>\n      <td>2</td>\n      <td>1</td>\n      <td>H</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2.10</td>\n      <td>-0.50</td>\n      <td>1.83</td>\n      <td>2.03</td>\n      <td>1.86</td>\n      <td>2.03</td>\n      <td>1.90</td>\n      <td>2.07</td>\n      <td>1.81</td>\n      <td>1.99</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>F2</td>\n      <td>13/01/2024</td>\n      <td>18:00</td>\n      <td>Troyes</td>\n      <td>Ajaccio</td>\n      <td>3</td>\n      <td>1</td>\n      <td>H</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.45</td>\n      <td>0.00</td>\n      <td>1.98</td>\n      <td>1.88</td>\n      <td>1.99</td>\n      <td>1.90</td>\n      <td>2.04</td>\n      <td>1.92</td>\n      <td>1.95</td>\n      <td>1.86</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>F2</td>\n      <td>13/01/2024</td>\n      <td>18:00</td>\n      <td>Valenciennes</td>\n      <td>Amiens</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.46</td>\n      <td>0.25</td>\n      <td>1.80</td>\n      <td>2.05</td>\n      <td>1.81</td>\n      <td>2.09</td>\n      <td>1.87</td>\n      <td>2.12</td>\n      <td>1.77</td>\n      <td>2.05</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>F2</td>\n      <td>15/01/2024</td>\n      <td>19:45</td>\n      <td>Auxerre</td>\n      <td>Bordeaux</td>\n      <td>3</td>\n      <td>1</td>\n      <td>H</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2.09</td>\n      <td>-0.50</td>\n      <td>1.93</td>\n      <td>1.93</td>\n      <td>1.92</td>\n      <td>1.97</td>\n      <td>1.93</td>\n      <td>2.15</td>\n      <td>1.84</td>\n      <td>1.95</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 105 columns</p>\n</div>"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#df = pd.read_csv('F2.csv')\n",
    "df = pd.read_csv('ligue_2.csv')\n",
    "#df = pd.read_csv('epl/E0 4.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "## Data Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.076084300Z",
     "start_time": "2024-01-24T00:34:00.045251900Z"
    }
   },
   "id": "c27a39651ea01908"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(Div         0\n Date        0\n Time        0\n HomeTeam    0\n AwayTeam    0\n            ..\n PCAHA       0\n MaxCAHH     0\n MaxCAHA     0\n AvgCAHH     0\n AvgCAHA     0\n Length: 105, dtype: int64,\n 0)"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# steps:\n",
    "# 1. Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# 2. Check for duplicates\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "# Display the results of the checks\n",
    "missing_values, duplicate_rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.192152700Z",
     "start_time": "2024-01-24T00:34:00.075083300Z"
    }
   },
   "id": "594bb92f2a11837b",
   "execution_count": 163
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "(Div         0\n Date        0\n Time        0\n HomeTeam    0\n AwayTeam    0\n            ..\n PCAHA       0\n MaxCAHH     0\n MaxCAHA     0\n AvgCAHH     0\n AvgCAHA     0\n Length: 105, dtype: int64,\n FTR\n H    80\n A    61\n D    59\n Name: count, dtype: int64)"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Checking the balance of the target variable 'FTR'\n",
    "target_distribution = df['FTR'].value_counts()\n",
    "\n",
    "# drop the div column\n",
    "df.drop('Div', axis=1, inplace=True)\n",
    "df.drop('Time', axis=1, inplace=True)\n",
    "\n",
    "missing_values, target_distribution\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.289081900Z",
     "start_time": "2024-01-24T00:34:00.125940600Z"
    }
   },
   "id": "598e531010defdf9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# covert date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.404231300Z",
     "start_time": "2024-01-24T00:34:00.201156400Z"
    }
   },
   "id": "e670089d22767e09",
   "execution_count": 165
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature engineering\n",
    "\n",
    "### steps:\n",
    "* Encode Team Names: Use label encoding for 'HomeTeam' and 'AwayTeam'. This will convert team names into numeric values, making them usable for the model.\n",
    "\n",
    "* Recent Form: Calculate the recent form for each team based on the last 5 matches. We'll use the 'FTR' column to determine wins (W), losses (L), and draws (D). This feature will provide insight into the current performance of the teams.\n",
    "\n",
    "* Average Goals per Game: Compute the average goals scored per game for both home and away teams. This feature helps understand the offensive strength of the teams.\n",
    "\n",
    "* Team Points: Calculate the total points accumulated by each team so far in the season. Points are awarded based on wins (3 points), draws (1 point), and losses (0 points).\n",
    "\n",
    "* Head-to-Head Statistics: Analyze the outcomes of matches between the same pairs of teams earlier in the season.\n",
    "\n",
    "* Other Statistical Features: Depending on the data available, we can include additional features like average possession, number of shots on target, defensive strength, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d8eb8645de65cd7"
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "# Reset the index of the DataFrame (if necessary)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rolling averages for goals\n",
    "window_sizes = [3, 5]\n",
    "for window in window_sizes:\n",
    "    df[f'HomeGoalsScoredAvg_{window}'] = df.groupby('HomeTeam')['FTHG'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "    df[f'AwayGoalsScoredAvg_{window}'] = df.groupby('AwayTeam')['FTAG'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "    df[f'HomeGoalsConcededAvg_{window}'] = df.groupby('HomeTeam')['FTAG'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "    df[f'AwayGoalsConcededAvg_{window}'] = df.groupby('AwayTeam')['FTHG'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.503723600Z",
     "start_time": "2024-01-24T00:34:00.409218600Z"
    }
   },
   "id": "555cad6dc030dab3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Variance in team performance\n",
    "df['HomeGoalsScoredVariance'] = df.groupby('HomeTeam')['FTHG'].transform(lambda x: x.rolling(5, min_periods=1).var())\n",
    "df['AwayGoalsScoredVariance'] = df.groupby('AwayTeam')['FTAG'].transform(lambda x: x.rolling(5, min_periods=1).var())\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.532839900Z",
     "start_time": "2024-01-24T00:34:00.467091600Z"
    }
   },
   "id": "b3bf9df58be1de92",
   "execution_count": 167
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ajaccio' 'Amiens' 'Angers' 'Annecy' 'Auxerre' 'Bastia' 'Bordeaux' 'Caen'\n",
      " 'Concarneau' 'Dunkerque' 'Grenoble' 'Guingamp' 'Laval' 'Paris FC'\n",
      " 'Pau FC' 'Quevilly Rouen' 'Rodez' 'St Etienne' 'Troyes' 'Valenciennes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Combine all unique team names from both HomeTeam and AwayTeam columns\n",
    "all_teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
    "\n",
    "# Fit the LabelEncoder with all unique team names\n",
    "label_encoder.fit(all_teams)\n",
    "\n",
    "# Transform both HomeTeam and AwayTeam using the fitted LabelEncoder\n",
    "df['HomeTeam_encoded'] = label_encoder.transform(df['HomeTeam'])\n",
    "df['AwayTeam_encoded'] = label_encoder.transform(df['AwayTeam'])\n",
    "\n",
    "# # Now you can transform individual team names\n",
    "# home_team_encoded = label_encoder.transform(['St Etienne'])[0]\n",
    "# away_team_encoded = label_encoder.transform(['Laval'])[0]\n",
    "\n",
    "# # Debugging: Print encoded values\n",
    "# print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "print(label_encoder.classes_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.634552900Z",
     "start_time": "2024-01-24T00:34:00.535835700Z"
    }
   },
   "id": "2b1a8cf45ea677d9",
   "execution_count": 168
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          Date        HomeTeam  AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  HS  \\\n195 2024-01-13  Quevilly Rouen  Guingamp     0     1   A     0     0   D  10   \n196 2024-01-13           Rodez    Pau FC     2     1   H     0     0   D  11   \n197 2024-01-13          Troyes   Ajaccio     3     1   H     1     1   D  12   \n198 2024-01-13    Valenciennes    Amiens     0     1   A     0     1   A  11   \n199 2024-01-15         Auxerre  Bordeaux     3     1   H     1     1   D  18   \n\n     ...  HomeGoalsConcededAvg_3  AwayGoalsConcededAvg_3  \\\n195  ...                1.000000                0.666667   \n196  ...                1.000000                1.333333   \n197  ...                1.666667                2.333333   \n198  ...                0.666667                1.333333   \n199  ...                1.000000                2.000000   \n\n     HomeGoalsScoredAvg_5  AwayGoalsScoredAvg_5  HomeGoalsConcededAvg_5  \\\n195                   1.4                   1.0                     1.2   \n196                   1.4                   1.2                     0.8   \n197                   1.6                   1.0                     1.4   \n198                   0.4                   1.0                     1.0   \n199                   2.6                   1.6                     1.2   \n\n     AwayGoalsConcededAvg_5  HomeGoalsScoredVariance  AwayGoalsScoredVariance  \\\n195                     0.4                      2.3                      1.5   \n196                     1.4                      0.8                      0.7   \n197                     1.8                      1.3                      1.5   \n198                     1.0                      0.8                      0.5   \n199                     2.0                      3.3                      0.3   \n\n     HomeTeam_encoded  AwayTeam_encoded  \n195                15                11  \n196                16                14  \n197                18                 0  \n198                19                 1  \n199                 4                 6  \n\n[5 rows x 115 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>HTR</th>\n      <th>HS</th>\n      <th>...</th>\n      <th>HomeGoalsConcededAvg_3</th>\n      <th>AwayGoalsConcededAvg_3</th>\n      <th>HomeGoalsScoredAvg_5</th>\n      <th>AwayGoalsScoredAvg_5</th>\n      <th>HomeGoalsConcededAvg_5</th>\n      <th>AwayGoalsConcededAvg_5</th>\n      <th>HomeGoalsScoredVariance</th>\n      <th>AwayGoalsScoredVariance</th>\n      <th>HomeTeam_encoded</th>\n      <th>AwayTeam_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>2024-01-13</td>\n      <td>Quevilly Rouen</td>\n      <td>Guingamp</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>0</td>\n      <td>0</td>\n      <td>D</td>\n      <td>10</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>1.2</td>\n      <td>0.4</td>\n      <td>2.3</td>\n      <td>1.5</td>\n      <td>15</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>2024-01-13</td>\n      <td>Rodez</td>\n      <td>Pau FC</td>\n      <td>2</td>\n      <td>1</td>\n      <td>H</td>\n      <td>0</td>\n      <td>0</td>\n      <td>D</td>\n      <td>11</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.333333</td>\n      <td>1.4</td>\n      <td>1.2</td>\n      <td>0.8</td>\n      <td>1.4</td>\n      <td>0.8</td>\n      <td>0.7</td>\n      <td>16</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>2024-01-13</td>\n      <td>Troyes</td>\n      <td>Ajaccio</td>\n      <td>3</td>\n      <td>1</td>\n      <td>H</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>12</td>\n      <td>...</td>\n      <td>1.666667</td>\n      <td>2.333333</td>\n      <td>1.6</td>\n      <td>1.0</td>\n      <td>1.4</td>\n      <td>1.8</td>\n      <td>1.3</td>\n      <td>1.5</td>\n      <td>18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>2024-01-13</td>\n      <td>Valenciennes</td>\n      <td>Amiens</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>11</td>\n      <td>...</td>\n      <td>0.666667</td>\n      <td>1.333333</td>\n      <td>0.4</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.8</td>\n      <td>0.5</td>\n      <td>19</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>2024-01-15</td>\n      <td>Auxerre</td>\n      <td>Bordeaux</td>\n      <td>3</td>\n      <td>1</td>\n      <td>H</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>18</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.6</td>\n      <td>1.6</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>3.3</td>\n      <td>0.3</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 115 columns</p>\n</div>"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.664832500Z",
     "start_time": "2024-01-24T00:34:00.607325400Z"
    }
   },
   "id": "68ab9522885d1ebc",
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Encoding the target variable 'FTR'\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variable using label_encoder_y\n",
    "df['FTR_encoded'] = label_encoder.fit_transform(df['FTR'])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.772301800Z",
     "start_time": "2024-01-24T00:34:00.667831300Z"
    }
   },
   "id": "fdeeda8cbb73755a",
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Average points per game\n",
    "df['HomeTeamPoints'] = df.groupby('HomeTeam')['FTR_encoded'].transform(lambda x: x.expanding().sum().shift(1)) / df.groupby('HomeTeam')['FTR_encoded'].transform(lambda x: x.expanding().count().shift(1))\n",
    "df['AwayTeamPoints'] = df.groupby('AwayTeam')['FTR_encoded'].transform(lambda x: x.expanding().sum().shift(1)) / df.groupby('AwayTeam')['FTR_encoded'].transform(lambda x: x.expanding().count().shift(1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:00.975129300Z",
     "start_time": "2024-01-24T00:34:00.775283300Z"
    }
   },
   "id": "a5308beebd3622e1",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Average goals per game\n",
    "df['HomeTeamAvgGoals'] = df.groupby('HomeTeam')['FTHG'].transform(lambda x: x.expanding().mean().shift(1)) # Average goals scored by the home team\n",
    "df['AwayTeamAvgGoals'] = df.groupby('AwayTeam')['FTAG'].transform(lambda x: x.expanding().mean().shift(1)) # Average goals scored by the away team\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:01.049496200Z",
     "start_time": "2024-01-24T00:34:00.923082Z"
    }
   },
   "id": "a9226672bfa2d435",
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# recent form\n",
    "def calculate_form_points(team, df):\n",
    "    # Get the last 5 matches of the home and away teams\n",
    "    home_matches = df[df['HomeTeam'] == team].tail(5)\n",
    "    away_matches = df[df['AwayTeam'] == team].tail(5)\n",
    "\n",
    "    # Calculate the points obtained in the last 5 matches\n",
    "    home_points = home_matches['FTR_encoded'].sum()\n",
    "    away_points = away_matches['FTR_encoded'].sum()\n",
    "\n",
    "    # Calculate the average points obtained\n",
    "    home_avg_points = home_points / 15\n",
    "    away_avg_points = away_points / 15\n",
    "\n",
    "    # Return the average points\n",
    "    return home_avg_points, away_avg_points\n",
    "\n",
    "# Calculate the average points obtained by each team in the last 5 matches\n",
    "df['HomeTeamRecentForm'], df['AwayTeamRecentForm'] = zip(*df['HomeTeam'].apply(lambda x: calculate_form_points(x, df)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:01.324962400Z",
     "start_time": "2024-01-24T00:34:00.996216300Z"
    }
   },
   "id": "7433bf2c3ef3a5e7",
   "execution_count": 173
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b8611cb69bd65f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recent Form"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f21cce905c91424"
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert 'Date' to datetime and extract useful features\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek  # 0: Monday, 6: Sunday\n",
    "df['IsWeekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)  # 1 for weekend, 0 for weekdays\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:01.325962900Z",
     "start_time": "2024-01-24T00:34:01.272050500Z"
    }
   },
   "id": "e80b6e05d39f4181"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:01.328960500Z",
     "start_time": "2024-01-24T00:34:01.281782300Z"
    }
   },
   "id": "3df868f314128140",
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#select relevant columns or features and the target\n",
    "features = [\n",
    "    'HomeTeam_encoded', 'AwayTeam_encoded', 'HomeTeamRecentForm', 'AwayTeamRecentForm', \n",
    "    'HomeTeamAvgGoals', 'AwayTeamAvgGoals', 'HomeTeamPoints', 'AwayTeamPoints', 'HomeGoalsScoredVariance', 'AwayGoalsScoredVariance', 'HomeGoalsScoredAvg_3', 'AwayGoalsScoredAvg_3', 'HomeGoalsConcededAvg_3', 'AwayGoalsConcededAvg_3', 'HomeGoalsScoredAvg_5', 'AwayGoalsScoredAvg_5', 'HomeGoalsConcededAvg_5', 'AwayGoalsConcededAvg_5',\n",
    "]\n",
    "\n",
    "target = 'FTR_encoded'\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Previewing the processed features\n",
    "X_train.head(7), y_train.head(7)\n",
    "\n",
    "# encoding the categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variable using label_encoder_y\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:01.354964200Z",
     "start_time": "2024-01-24T00:34:01.286283900Z"
    }
   },
   "id": "5c1fefe366e02665",
   "execution_count": 175
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both the training and testing sets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:01.356975400Z",
     "start_time": "2024-01-24T00:34:01.308593400Z"
    }
   },
   "id": "474e0ec0b8de5c52",
   "execution_count": 176
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1ad0e76308763b7"
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 350\n",
      "[LightGBM] [Info] Number of data points in the train set: 160, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score -1.225026\n",
      "[LightGBM] [Info] Start training from score -1.086190\n",
      "[LightGBM] [Info] Start training from score -0.997636\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x195040df0d0>"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize the models\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "lgbm_model = LGBMClassifier(random_state=42)   \n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=False)\n",
    "\n",
    "\n",
    "# Train the models\n",
    "#rf_model.fit(X_train, y_train_encoded)\n",
    "xgb_model.fit(X_train_scaled, y_train_encoded)\n",
    "lgbm_model.fit(X_train_scaled, y_train_encoded)\n",
    "catboost_model.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:12.757284900Z",
     "start_time": "2024-01-24T00:34:01.327965300Z"
    }
   },
   "id": "8b40589ac3bdd675"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Metrics\n",
      "Accuracy: 0.275\n",
      "Precision: 0.4656084656084656\n",
      "Recall: 0.3428571428571428\n",
      "F1 Score: 0.27414021164021163\n",
      "\n",
      "\n",
      "LightGBM Model Metrics\n",
      "Accuracy: 0.25\n",
      "Precision: 0.5106732348111659\n",
      "Recall: 0.3349206349206349\n",
      "F1 Score: 0.2607282913165266\n",
      "\n",
      "\n",
      "CatBoost Model Metrics\n",
      "Accuracy: 0.225\n",
      "Precision: 0.38095238095238093\n",
      "Recall: 0.3460317460317461\n",
      "F1 Score: 0.209013209013209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#evaluate the models using the metrics\n",
    "models = [ xgb_model, lgbm_model, catboost_model]\n",
    "model_names = [ 'XGBoost', 'LightGBM', 'CatBoost', 'AdaBoost']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    print(f\"{name} Model Metrics\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:12.781162800Z",
     "start_time": "2024-01-24T00:34:12.743293700Z"
    }
   },
   "id": "70ee9938150d56d0",
   "execution_count": 178
  },
  {
   "cell_type": "markdown",
   "source": [
    "# creating objective function and hyper opts for hyperparaemters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13cdd496a3827382"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "# Define the hyperparameter space\n",
    "space = {\n",
    "    'iterations': hp.quniform('iterations', 100, 1000, 50),\n",
    "    'depth': hp.choice('depth', np.arange(3, 11, dtype=int)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 1, 10),\n",
    "    'bagging_temperature': hp.uniform('bagging_temperature', 0, 1),\n",
    "    'random_strength': hp.uniform('random_strength', 0, 1),\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:12.812766300Z",
     "start_time": "2024-01-24T00:34:12.777834Z"
    }
   },
   "id": "c45184c63a52bac",
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import STATUS_OK\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    params['iterations'] = int(params['iterations'])\n",
    "    clf = CatBoostClassifier(**params, loss_function='MultiClass', verbose=False)\n",
    "    score = cross_val_score(clf, X_train_scaled, y_train_encoded, scoring='accuracy', cv=StratifiedKFold(10)).mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:34:12.853763700Z",
     "start_time": "2024-01-24T00:34:12.783168700Z"
    }
   },
   "id": "5217c545333449f8",
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [05:19<00:00, 31.90s/trial, best loss: -0.65625]\n"
     ]
    }
   ],
   "source": [
    "# run the hyperparameter optimization\n",
    "from hyperopt import tpe, Trials, fmin\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10, trials=trials)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:39:31.858720800Z",
     "start_time": "2024-01-24T00:34:12.799767500Z"
    }
   },
   "id": "53baa390efcb2685",
   "execution_count": 181
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        14\n",
      "           1       0.31      0.80      0.44         5\n",
      "           2       0.89      0.76      0.82        21\n",
      "\n",
      "    accuracy                           0.73        40\n",
      "   macro avg       0.73      0.73      0.68        40\n",
      "weighted avg       0.86      0.72      0.76        40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_params = {k: int(v) if k in ['iterations', 'depth'] else v for k, v in best.items()}\n",
    "final_model = CatBoostClassifier(**best_params, loss_function='MultiClass', eval_metric='Accuracy', verbose=False)\n",
    "final_model.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:39:32.708254100Z",
     "start_time": "2024-01-24T00:39:31.860723500Z"
    }
   },
   "id": "99a573068f7b01fa",
   "execution_count": 182
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Xgboost with params"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ad34a565de1fb1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# hyperparameter tuning for xgboost using hyperopt\n",
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "# Define the hyperparameter space\n",
    "\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 1000, 50),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(3, 11, dtype=int)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 1, 10),\n",
    "    'gamma': hp.uniform('gamma', 0, 1),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0, 10)\n",
    "    \n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:42:03.195195400Z",
     "start_time": "2024-01-24T00:42:03.165443800Z"
    }
   },
   "id": "1933b5eb7cbf2fa5",
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def objective(params):\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    clf = XGBClassifier(**params, objective='multi:softmax', num_class=3, eval_metric='mlogloss', verbosity=0)\n",
    "    score = cross_val_score(clf, X_train_scaled, y_train_encoded, scoring='accuracy', cv=StratifiedKFold(10)).mean()\n",
    "    return {'loss': -score, 'status': STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:42:48.458818600Z",
     "start_time": "2024-01-24T00:42:48.433846900Z"
    }
   },
   "id": "9034765646a2ea09",
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:36<00:00,  3.66s/trial, best loss: -0.60625]\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='mlogloss',\n              feature_types=None, gamma=0.13595062091986387, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.017001695452465222, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=6.415568470849655, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=700,\n              n_jobs=None, num_class=3, num_parallel_tree=None, ...)",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=0.13595062091986387, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.017001695452465222, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=6.415568470849655, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=700,\n              n_jobs=None, num_class=3, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=0.13595062091986387, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.017001695452465222, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=6.415568470849655, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=700,\n              n_jobs=None, num_class=3, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the hyperparameter optimization\n",
    "from hyperopt import tpe, Trials, fmin\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_params = {k: int(v) if k in ['n_estimators', 'max_depth'] else v for k, v in best.items()}\n",
    "best_model_2 = XGBClassifier(**best_params, objective='multi:softmax', num_class=3, eval_metric='mlogloss', verbosity=0)\n",
    "best_model_2.fit(X_train_scaled, y_train_encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:44:07.441680100Z",
     "start_time": "2024-01-24T00:43:30.647774100Z"
    }
   },
   "id": "a00c50b1f242c6a9",
   "execution_count": 193
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67        14\n",
      "           1       0.22      0.40      0.29         5\n",
      "           2       0.76      0.76      0.76        21\n",
      "\n",
      "    accuracy                           0.65        40\n",
      "   macro avg       0.59      0.58      0.57        40\n",
      "weighted avg       0.71      0.65      0.67        40\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = best_model_2.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "\n",
    "      "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:44:48.617287400Z",
     "start_time": "2024-01-24T00:44:48.580345700Z"
    }
   },
   "id": "91e7aa843f4b18c4",
   "execution_count": 196
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ajaccio' 'Amiens' 'Angers' 'Annecy' 'Auxerre' 'Bastia' 'Bordeaux' 'Caen'\n",
      " 'Concarneau' 'Dunkerque' 'Grenoble' 'Guingamp' 'Laval' 'Paris FC'\n",
      " 'Pau FC' 'Quevilly Rouen' 'Rodez' 'St Etienne' 'Troyes' 'Valenciennes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Combine all unique team names from both HomeTeam and AwayTeam columns\n",
    "all_teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
    "\n",
    "# Fit the LabelEncoder with all unique team names\n",
    "label_encoder.fit(all_teams)\n",
    "\n",
    "# Transform both HomeTeam and AwayTeam using the fitted LabelEncoder\n",
    "df['HomeTeam_encoded'] = label_encoder.transform(df['HomeTeam'])\n",
    "df['AwayTeam_encoded'] = label_encoder.transform(df['AwayTeam'])\n",
    "\n",
    "# # Now you can transform individual team names\n",
    "# home_team_encoded = label_encoder.transform(['St Etienne'])[0]\n",
    "# away_team_encoded = label_encoder.transform(['Laval'])[0]\n",
    "# \n",
    "# # Debugging: Print encoded values\n",
    "# print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "print(label_encoder.classes_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:39:32.709256800Z",
     "start_time": "2024-01-24T00:39:32.698647400Z"
    }
   },
   "id": "46326b9866c00cf4",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Today's matches\n",
      "Encoded Home Team: 1, Encoded Away Team: 3\n",
      "Amiens win probability: 0.3297712504863739\n",
      "Draw probability: 0.6173827648162842\n",
      "Annecy win probability: 0.05284600704908371\n",
      "Encoded Home Team: 2, Encoded Away Team: 15\n",
      "Angers win probability: 0.12891191244125366\n",
      "Draw probability: 0.5698744654655457\n",
      "Quevilly Rouen win probability: 0.30121365189552307\n",
      "Encoded Home Team: 6, Encoded Away Team: 19\n",
      "Bordeaux win probability: 0.4814999997615814\n",
      "Draw probability: 0.42215490341186523\n",
      "Valenciennes win probability: 0.09634514153003693\n",
      "Encoded Home Team: 8, Encoded Away Team: 18\n",
      "Concarneau win probability: 0.17260992527008057\n",
      "Draw probability: 0.8124164938926697\n",
      "Troyes win probability: 0.01497358363121748\n",
      "Encoded Home Team: 9, Encoded Away Team: 0\n",
      "Dunkerque win probability: 0.7940241694450378\n",
      "Draw probability: 0.08733724057674408\n",
      "Ajaccio win probability: 0.11863861232995987\n",
      "Encoded Home Team: 11, Encoded Away Team: 16\n",
      "Guingamp win probability: 0.1839970350265503\n",
      "Draw probability: 0.7340702414512634\n",
      "Rodez win probability: 0.08193273842334747\n",
      "Encoded Home Team: 12, Encoded Away Team: 13\n",
      "Laval win probability: 0.12997105717658997\n",
      "Draw probability: 0.8601587414741516\n",
      "Paris FC win probability: 0.009870169684290886\n",
      "Encoded Home Team: 14, Encoded Away Team: 17\n",
      "Pau FC win probability: 0.32447174191474915\n",
      "Draw probability: 0.2828565239906311\n",
      "St Etienne win probability: 0.39267170429229736\n",
      "Encoded Home Team: 5, Encoded Away Team: 7\n",
      "Bastia win probability: 0.29326000809669495\n",
      "Draw probability: 0.49330800771713257\n",
      "Caen win probability: 0.21343201398849487\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.29326, 0.493308, 0.21343201)"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_match(home_team, away_team, xgb_model, df, label_encoder):\n",
    "     # Debugging: Check if the team names are in label_encoder's classes\n",
    "    if home_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Home team name '{home_team}' not recognized.\")\n",
    "    if away_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Away team name '{away_team}' not recognized.\")\n",
    "\n",
    "    # Transform team names\n",
    "    home_team_encoded = label_encoder.transform([home_team])[0]\n",
    "    away_team_encoded = label_encoder.transform([away_team])[0]\n",
    "\n",
    "    # Debugging: Print encoded values\n",
    "    print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "    # Prepare the match data with relevant features\n",
    "    match_data = {\n",
    "        'HomeTeam_encoded': label_encoder.transform([home_team])[0],\n",
    "        'AwayTeam_encoded': label_encoder.transform([away_team])[0],\n",
    "        'HomeTeamRecentForm': calculate_form_points(home_team, df)[0],\n",
    "        'AwayTeamRecentForm': calculate_form_points(away_team, df)[1],\n",
    "        'HomeTeamAvgGoals': df[df['HomeTeam'] == home_team]['FTHG'].mean(),\n",
    "        'AwayTeamAvgGoals': df[df['AwayTeam'] == away_team]['FTAG'].mean(),\n",
    "        'HomeTeamPoints': df[df['HomeTeam'] == home_team]['FTR_encoded'].sum() / df[df['HomeTeam'] == home_team]['FTR_encoded'].count(),\n",
    "        'AwayTeamPoints': df[df['AwayTeam'] == away_team]['FTR_encoded'].sum() / df[df['AwayTeam'] == away_team]['FTR_encoded'].count(),\n",
    "        'HomeGoalsScoredVariance': df[df['HomeTeam'] == home_team]['FTHG'].var(),\n",
    "        'AwayGoalsScoredVariance': df[df['AwayTeam'] == away_team]['FTAG'].var(),\n",
    "        'HomeGoalsScoredAvg_3': df[df['HomeTeam'] == home_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_3': df[df['AwayTeam'] == away_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_3': df[df['HomeTeam'] == home_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_3': df[df['AwayTeam'] == away_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsScoredAvg_5': df[df['HomeTeam'] == home_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_5': df[df['AwayTeam'] == away_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_5': df[df['HomeTeam'] == home_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_5': df[df['AwayTeam'] == away_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        \n",
    "        # Add other features as required by the model, calculated or retrieved as done during training\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    match_df = pd.DataFrame([match_data])\n",
    "\n",
    "    # Make predictions\n",
    "    probabilities = xgb_model.predict_proba(match_df)[0]\n",
    "    home_team_win_prob = probabilities[0]\n",
    "    draw_prob = probabilities[1]\n",
    "    away_team_win_prob = probabilities[2]\n",
    "\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "\n",
    "    return home_team_win_prob, draw_prob, away_team_win_prob\n",
    "\n",
    "\n",
    "\n",
    "print('##########################')\n",
    "print('Today\\'s matches')\n",
    "\n",
    "predict_match('Amiens', 'Annecy', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Angers', 'Quevilly Rouen', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Bordeaux', 'Valenciennes', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Concarneau', 'Troyes', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Dunkerque', 'Ajaccio', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Guingamp', 'Rodez', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Laval', 'Paris FC', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Pau FC', 'St Etienne', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Bastia', 'Caen', xgb_model, df, label_encoder)\n",
    "\n",
    "# predict_match('Sheffield United', 'West Ham', xgb_model, df, label_encoder)\n",
    "# \n",
    "# predict_match('Bournemouth', 'Liverpool', xgb_model, df, label_encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:39:32.881239400Z",
     "start_time": "2024-01-24T00:39:32.702248500Z"
    }
   },
   "id": "fc7f5a44c0b70d65"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# xgboost with hyperprams predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd05b123b79ac471"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Today's matches\n",
      "Encoded Home Team: 1, Encoded Away Team: 3\n",
      "Amiens win probability: 0.29702356457710266\n",
      "Draw probability: 0.29851263761520386\n",
      "Annecy win probability: 0.4044637382030487\n",
      "Encoded Home Team: 2, Encoded Away Team: 15\n",
      "Angers win probability: 0.2844446301460266\n",
      "Draw probability: 0.28587064146995544\n",
      "Quevilly Rouen win probability: 0.42968469858169556\n",
      "Encoded Home Team: 6, Encoded Away Team: 19\n",
      "Bordeaux win probability: 0.3038293719291687\n",
      "Draw probability: 0.29562264680862427\n",
      "Valenciennes win probability: 0.4005480110645294\n",
      "Encoded Home Team: 8, Encoded Away Team: 18\n",
      "Concarneau win probability: 0.3087896704673767\n",
      "Draw probability: 0.3004489541053772\n",
      "Troyes win probability: 0.3907614052295685\n",
      "Encoded Home Team: 9, Encoded Away Team: 0\n",
      "Dunkerque win probability: 0.4879855811595917\n",
      "Draw probability: 0.2985893487930298\n",
      "Ajaccio win probability: 0.21342508494853973\n",
      "Encoded Home Team: 11, Encoded Away Team: 16\n",
      "Guingamp win probability: 0.3038293719291687\n",
      "Draw probability: 0.29562264680862427\n",
      "Rodez win probability: 0.4005480110645294\n",
      "Encoded Home Team: 12, Encoded Away Team: 13\n",
      "Laval win probability: 0.3087896704673767\n",
      "Draw probability: 0.3004489541053772\n",
      "Paris FC win probability: 0.3907614052295685\n",
      "Encoded Home Team: 14, Encoded Away Team: 17\n",
      "Pau FC win probability: 0.29702356457710266\n",
      "Draw probability: 0.29851263761520386\n",
      "St Etienne win probability: 0.4044637382030487\n",
      "Encoded Home Team: 5, Encoded Away Team: 7\n",
      "Bastia win probability: 0.2844446301460266\n",
      "Draw probability: 0.28587064146995544\n",
      "Caen win probability: 0.42968469858169556\n",
      "Encoded Home Team: 10, Encoded Away Team: 4\n",
      "Grenoble win probability: 0.3011709451675415\n",
      "Draw probability: 0.3037605881690979\n",
      "Auxerre win probability: 0.3950684666633606\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.30117095, 0.3037606, 0.39506847)"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_match(home_team, away_team, best_model_2, df, label_encoder):\n",
    "     # Debugging: Check if the team names are in label_encoder's classes\n",
    "    if home_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Home team name '{home_team}' not recognized.\")\n",
    "    if away_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Away team name '{away_team}' not recognized.\")\n",
    "\n",
    "    # Transform team names\n",
    "    home_team_encoded = label_encoder.transform([home_team])[0]\n",
    "    away_team_encoded = label_encoder.transform([away_team])[0]\n",
    "\n",
    "    # Debugging: Print encoded values\n",
    "    print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "    # Prepare the match data with relevant features\n",
    "    match_data = {\n",
    "        'HomeTeam_encoded': label_encoder.transform([home_team])[0],\n",
    "        'AwayTeam_encoded': label_encoder.transform([away_team])[0],\n",
    "        'HomeTeamRecentForm': calculate_form_points(home_team, df)[0],\n",
    "        'AwayTeamRecentForm': calculate_form_points(away_team, df)[1],\n",
    "        'HomeTeamAvgGoals': df[df['HomeTeam'] == home_team]['FTHG'].mean(),\n",
    "        'AwayTeamAvgGoals': df[df['AwayTeam'] == away_team]['FTAG'].mean(),\n",
    "        'HomeTeamPoints': df[df['HomeTeam'] == home_team]['FTR_encoded'].sum() / df[df['HomeTeam'] == home_team]['FTR_encoded'].count(),\n",
    "        'AwayTeamPoints': df[df['AwayTeam'] == away_team]['FTR_encoded'].sum() / df[df['AwayTeam'] == away_team]['FTR_encoded'].count(),\n",
    "        'HomeGoalsScoredVariance': df[df['HomeTeam'] == home_team]['FTHG'].var(),\n",
    "        'AwayGoalsScoredVariance': df[df['AwayTeam'] == away_team]['FTAG'].var(),\n",
    "        'HomeGoalsScoredAvg_3': df[df['HomeTeam'] == home_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_3': df[df['AwayTeam'] == away_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_3': df[df['HomeTeam'] == home_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_3': df[df['AwayTeam'] == away_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsScoredAvg_5': df[df['HomeTeam'] == home_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_5': df[df['AwayTeam'] == away_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_5': df[df['HomeTeam'] == home_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_5': df[df['AwayTeam'] == away_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        \n",
    "        # Add other features as required by the model, calculated or retrieved as done during training\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    match_df = pd.DataFrame([match_data])\n",
    "\n",
    "    # Make predictions\n",
    "    probabilities = best_model_2.predict_proba(match_df)[0]\n",
    "    home_team_win_prob = probabilities[0]\n",
    "    draw_prob = probabilities[1]\n",
    "    away_team_win_prob = probabilities[2]\n",
    "\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "\n",
    "    return home_team_win_prob, draw_prob, away_team_win_prob\n",
    "\n",
    "\n",
    "\n",
    "print('##########################')\n",
    "print('Today\\'s matches')\n",
    "\n",
    "predict_match('Amiens', 'Annecy', best_model_2, df, label_encoder)\n",
    "\n",
    "predict_match('Angers', 'Quevilly Rouen', best_model_2, df, label_encoder)\n",
    "\n",
    "predict_match('Bordeaux', 'Valenciennes', best_model_2, df, label_encoder)\n",
    "\n",
    "predict_match('Concarneau', 'Troyes', best_model_2, df, label_encoder)\n",
    "\n",
    "predict_match('Dunkerque', 'Ajaccio', best_model_2, df, label_encoder)\n",
    "\n",
    "predict_match('Guingamp', 'Rodez', best_model_2, df, label_encoder)\n",
    "\n",
    "predict_match('Laval', 'Paris FC', best_model_2, df, label_encoder)\n",
    "\n",
    "predict_match('Pau FC', 'St Etienne', best_model_2, df, label_encoder)\n",
    "\n",
    "predict_match('Bastia', 'Caen', best_model_2, df, label_encoder)\n",
    "\n",
    "predict_match('Grenoble', 'Auxerre', best_model_2, df, label_encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:48:56.173046700Z",
     "start_time": "2024-01-24T00:48:55.962013100Z"
    }
   },
   "id": "586417e8a4d7813",
   "execution_count": 197
  },
  {
   "cell_type": "markdown",
   "source": [
    "# catboost with hyperparameter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb8bc92fa5201125"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's matches\n",
      "Encoded Home Team: 1, Encoded Away Team: 3\n",
      "Amiens win probability: 0.2761832621146922\n",
      "Draw probability: 0.34683061143588423\n",
      "Annecy win probability: 0.37698612644942353\n",
      "Encoded Home Team: 2, Encoded Away Team: 15\n",
      "Angers win probability: 0.285857621591056\n",
      "Draw probability: 0.32580422267780695\n",
      "Quevilly Rouen win probability: 0.3883381557311371\n",
      "Encoded Home Team: 6, Encoded Away Team: 19\n",
      "Bordeaux win probability: 0.2749811969814781\n",
      "Draw probability: 0.3499158274161195\n",
      "Valenciennes win probability: 0.37510297560240247\n",
      "Encoded Home Team: 8, Encoded Away Team: 18\n",
      "Concarneau win probability: 0.27640567800701127\n",
      "Draw probability: 0.3749205156972292\n",
      "Troyes win probability: 0.3486738062957595\n",
      "Encoded Home Team: 9, Encoded Away Team: 0\n",
      "Dunkerque win probability: 0.33224779935400117\n",
      "Draw probability: 0.35225227973837886\n",
      "Ajaccio win probability: 0.31549992090762\n",
      "Encoded Home Team: 11, Encoded Away Team: 16\n",
      "Guingamp win probability: 0.28017029808163113\n",
      "Draw probability: 0.3526756635335448\n",
      "Rodez win probability: 0.3671540383848241\n",
      "Encoded Home Team: 12, Encoded Away Team: 13\n",
      "Laval win probability: 0.29287218454762387\n",
      "Draw probability: 0.3788115814362983\n",
      "Paris FC win probability: 0.3283162340160778\n",
      "Encoded Home Team: 14, Encoded Away Team: 17\n",
      "Pau FC win probability: 0.2776836595208591\n",
      "Draw probability: 0.349172939142438\n",
      "St Etienne win probability: 0.3731434013367028\n",
      "Encoded Home Team: 5, Encoded Away Team: 7\n",
      "Bastia win probability: 0.2882562238248832\n",
      "Draw probability: 0.3221720745435194\n",
      "Caen win probability: 0.38957170163159727\n",
      "Encoded Home Team: 10, Encoded Away Team: 4\n",
      "Grenoble win probability: 0.2753972886339138\n",
      "Draw probability: 0.3682836562919781\n",
      "Auxerre win probability: 0.35631905507410816\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.2753972886339138, 0.3682836562919781, 0.35631905507410816)"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_match(home_team, away_team, final_model, df, label_encoder):\n",
    "     # Debugging: Check if the team names are in label_encoder's classes\n",
    "    if home_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Home team name '{home_team}' not recognized.\")\n",
    "    if away_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Away team name '{away_team}' not recognized.\")\n",
    "\n",
    "    # Transform team names\n",
    "    home_team_encoded = label_encoder.transform([home_team])[0]\n",
    "    away_team_encoded = label_encoder.transform([away_team])[0]\n",
    "\n",
    "    # Debugging: Print encoded values\n",
    "    print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "    # Prepare the match data with relevant features\n",
    "    match_data = {\n",
    "        'HomeTeam_encoded': label_encoder.transform([home_team])[0],\n",
    "        'AwayTeam_encoded': label_encoder.transform([away_team])[0],\n",
    "        'HomeTeamRecentForm': calculate_form_points(home_team, df)[0],\n",
    "        'AwayTeamRecentForm': calculate_form_points(away_team, df)[1],\n",
    "        'HomeTeamAvgGoals': df[df['HomeTeam'] == home_team]['FTHG'].mean(),\n",
    "        'AwayTeamAvgGoals': df[df['AwayTeam'] == away_team]['FTAG'].mean(),\n",
    "        'HomeTeamPoints': df[df['HomeTeam'] == home_team]['FTR_encoded'].sum() / df[df['HomeTeam'] == home_team]['FTR_encoded'].count(),\n",
    "        'AwayTeamPoints': df[df['AwayTeam'] == away_team]['FTR_encoded'].sum() / df[df['AwayTeam'] == away_team]['FTR_encoded'].count(),\n",
    "        'HomeGoalsScoredVariance': df[df['HomeTeam'] == home_team]['FTHG'].var(),\n",
    "        'AwayGoalsScoredVariance': df[df['AwayTeam'] == away_team]['FTAG'].var(),\n",
    "        'HomeGoalsScoredAvg_3': df[df['HomeTeam'] == home_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_3': df[df['AwayTeam'] == away_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_3': df[df['HomeTeam'] == home_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_3': df[df['AwayTeam'] == away_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsScoredAvg_5': df[df['HomeTeam'] == home_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_5': df[df['AwayTeam'] == away_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_5': df[df['HomeTeam'] == home_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_5': df[df['AwayTeam'] == away_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        \n",
    "        # Add other features as required by the model, calculated or retrieved as done during training\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    match_df = pd.DataFrame([match_data])\n",
    "\n",
    "    # Make predictions\n",
    "    probabilities = final_model.predict_proba(match_df)[0]\n",
    "    home_team_win_prob = probabilities[0]\n",
    "    draw_prob = probabilities[1]\n",
    "    away_team_win_prob = probabilities[2]\n",
    "\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "\n",
    "    return home_team_win_prob, draw_prob, away_team_win_prob\n",
    "\n",
    "print('Today\\'s matches')\n",
    "\n",
    "predict_match('Amiens', 'Annecy', final_model, df, label_encoder)\n",
    "\n",
    "predict_match('Angers', 'Quevilly Rouen', final_model, df, label_encoder)\n",
    "\n",
    "predict_match('Bordeaux', 'Valenciennes', final_model, df, label_encoder)\n",
    "\n",
    "predict_match('Concarneau', 'Troyes', final_model, df, label_encoder)\n",
    "\n",
    "predict_match('Dunkerque', 'Ajaccio', final_model, df, label_encoder)\n",
    "\n",
    "predict_match('Guingamp', 'Rodez', final_model, df, label_encoder)\n",
    "\n",
    "predict_match('Laval', 'Paris FC', final_model, df, label_encoder)\n",
    "\n",
    "predict_match('Pau FC', 'St Etienne', final_model, df, label_encoder)\n",
    "\n",
    "predict_match('Bastia', 'Caen', final_model, df, label_encoder)\n",
    "\n",
    "predict_match('Grenoble', 'Auxerre', final_model, df, label_encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:39:33.083622400Z",
     "start_time": "2024-01-24T00:39:32.881239400Z"
    }
   },
   "id": "f0d5227de6b197e7",
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Today's matches\n",
      "Encoded Home Team: 1, Encoded Away Team: 3\n",
      "Amiens win probability: 0.437402478311337\n",
      "Draw probability: 0.3608135005431558\n",
      "Annecy win probability: 0.20178402114550714\n",
      "Encoded Home Team: 2, Encoded Away Team: 15\n",
      "Angers win probability: 0.36771253137539134\n",
      "Draw probability: 0.3454135584347304\n",
      "Quevilly Rouen win probability: 0.2868739101898782\n",
      "Encoded Home Team: 6, Encoded Away Team: 19\n",
      "Bordeaux win probability: 0.4036275505763567\n",
      "Draw probability: 0.40156919408249653\n",
      "Valenciennes win probability: 0.19480325534114687\n",
      "Encoded Home Team: 8, Encoded Away Team: 18\n",
      "Concarneau win probability: 0.28516116388787066\n",
      "Draw probability: 0.5685205471346554\n",
      "Troyes win probability: 0.146318288977474\n",
      "Encoded Home Team: 9, Encoded Away Team: 0\n",
      "Dunkerque win probability: 0.5432330463279129\n",
      "Draw probability: 0.31439639214400367\n",
      "Ajaccio win probability: 0.14237056152808333\n",
      "Encoded Home Team: 11, Encoded Away Team: 16\n",
      "Guingamp win probability: 0.3980515676352216\n",
      "Draw probability: 0.41660533996669796\n",
      "Rodez win probability: 0.18534309239808042\n",
      "Encoded Home Team: 12, Encoded Away Team: 13\n",
      "Laval win probability: 0.3703852253345421\n",
      "Draw probability: 0.534327493200245\n",
      "Paris FC win probability: 0.09528728146521293\n",
      "Encoded Home Team: 14, Encoded Away Team: 17\n",
      "Pau FC win probability: 0.3743155762960456\n",
      "Draw probability: 0.3883942255414044\n",
      "St Etienne win probability: 0.23729019816254984\n",
      "Encoded Home Team: 5, Encoded Away Team: 7\n",
      "Bastia win probability: 0.43520478221026415\n",
      "Draw probability: 0.32926718127872423\n",
      "Caen win probability: 0.2355280365110116\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.43520478221026415, 0.32926718127872423, 0.2355280365110116)"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_match(home_team, away_team, catboost_model, df, label_encoder):\n",
    "     # Debugging: Check if the team names are in label_encoder's classes\n",
    "    if home_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Home team name '{home_team}' not recognized.\")\n",
    "    if away_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Away team name '{away_team}' not recognized.\")\n",
    "\n",
    "    # Transform team names\n",
    "    home_team_encoded = label_encoder.transform([home_team])[0]\n",
    "    away_team_encoded = label_encoder.transform([away_team])[0]\n",
    "\n",
    "    # Debugging: Print encoded values\n",
    "    print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "    # Prepare the match data with relevant features\n",
    "    match_data = {\n",
    "        'HomeTeam_encoded': label_encoder.transform([home_team])[0],\n",
    "        'AwayTeam_encoded': label_encoder.transform([away_team])[0],\n",
    "        'HomeTeamRecentForm': calculate_form_points(home_team, df)[0],\n",
    "        'AwayTeamRecentForm': calculate_form_points(away_team, df)[1],\n",
    "        'HomeTeamAvgGoals': df[df['HomeTeam'] == home_team]['FTHG'].mean(),\n",
    "        'AwayTeamAvgGoals': df[df['AwayTeam'] == away_team]['FTAG'].mean(),\n",
    "        'HomeTeamPoints': df[df['HomeTeam'] == home_team]['FTR_encoded'].sum() / df[df['HomeTeam'] == home_team]['FTR_encoded'].count(),\n",
    "        'AwayTeamPoints': df[df['AwayTeam'] == away_team]['FTR_encoded'].sum() / df[df['AwayTeam'] == away_team]['FTR_encoded'].count(),\n",
    "        'HomeGoalsScoredVariance': df[df['HomeTeam'] == home_team]['FTHG'].var(),\n",
    "        'AwayGoalsScoredVariance': df[df['AwayTeam'] == away_team]['FTAG'].var(),\n",
    "        'HomeGoalsScoredAvg_3': df[df['HomeTeam'] == home_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_3': df[df['AwayTeam'] == away_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_3': df[df['HomeTeam'] == home_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_3': df[df['AwayTeam'] == away_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsScoredAvg_5': df[df['HomeTeam'] == home_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_5': df[df['AwayTeam'] == away_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_5': df[df['HomeTeam'] == home_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_5': df[df['AwayTeam'] == away_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        \n",
    "        # Add other features as required by the model, calculated or retrieved as done during training\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    match_df = pd.DataFrame([match_data])\n",
    "\n",
    "    # Make predictions\n",
    "    probabilities = catboost_model.predict_proba(match_df)[0]\n",
    "    home_team_win_prob = probabilities[0]\n",
    "    draw_prob = probabilities[1]\n",
    "    away_team_win_prob = probabilities[2]\n",
    "\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "\n",
    "    return home_team_win_prob, draw_prob, away_team_win_prob\n",
    "\n",
    "\n",
    "\n",
    "print('##########################')\n",
    "print('Today\\'s matches')\n",
    "\n",
    "predict_match('Amiens', 'Annecy', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Angers', 'Quevilly Rouen', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Bordeaux', 'Valenciennes', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Concarneau', 'Troyes', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Dunkerque', 'Ajaccio', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Guingamp', 'Rodez', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Laval', 'Paris FC', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Pau FC', 'St Etienne', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Bastia', 'Caen', catboost_model, df, label_encoder)\n",
    "\n",
    "# predict_match('Sheffield United', 'West Ham', catboost_model, df, label_encoder)\n",
    "# \n",
    "# predict_match('Bournemouth', 'Liverpool', catboost_model, df, label_encoder)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:39:33.238809300Z",
     "start_time": "2024-01-24T00:39:33.091620500Z"
    }
   },
   "id": "d4aaf95550397fc0",
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the imputer (you can change the strategy to 'median' or 'most_frequent' if more appropriate)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Fit on the training data and transform both training and testing data\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:39:33.258735700Z",
     "start_time": "2024-01-24T00:39:33.239798100Z"
    }
   },
   "id": "5afcd0ee014014b1",
   "execution_count": 187
  },
  {
   "cell_type": "markdown",
   "source": [
    "## using random forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd674d54c6445cb0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.70        14\n",
      "           1       0.25      0.60      0.35         5\n",
      "           2       0.89      0.81      0.85        21\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.68      0.66      0.63        40\n",
      "weighted avg       0.81      0.70      0.73        40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Then scale the imputed data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "    \n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1_macro')\n",
    "grid_search.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Best Model Evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:41:19.396880Z",
     "start_time": "2024-01-24T00:39:33.255177900Z"
    }
   },
   "id": "561f276f86e12a37",
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Today's matches\n",
      "Encoded Home Team: 1, Encoded Away Team: 3\n",
      "Amiens win probability: 0.12\n",
      "Annecy win probability: 0.24\n",
      "Draw probability: 0.64\n",
      "Encoded Home Team: 2, Encoded Away Team: 15\n",
      "Angers win probability: 0.11\n",
      "Quevilly Rouen win probability: 0.81\n",
      "Draw probability: 0.08\n",
      "Encoded Home Team: 6, Encoded Away Team: 19\n",
      "Bordeaux win probability: 0.24\n",
      "Valenciennes win probability: 0.21\n",
      "Draw probability: 0.55\n",
      "Encoded Home Team: 8, Encoded Away Team: 18\n",
      "Concarneau win probability: 0.45\n",
      "Troyes win probability: 0.15\n",
      "Draw probability: 0.4\n",
      "Encoded Home Team: 9, Encoded Away Team: 0\n",
      "Dunkerque win probability: 0.63\n",
      "Ajaccio win probability: 0.13\n",
      "Draw probability: 0.24\n",
      "Encoded Home Team: 11, Encoded Away Team: 16\n",
      "Guingamp win probability: 0.34"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rodez win probability: 0.1\n",
      "Draw probability: 0.56\n",
      "Encoded Home Team: 12, Encoded Away Team: 13\n",
      "Laval win probability: 0.69\n",
      "Paris FC win probability: 0.01\n",
      "Draw probability: 0.3\n",
      "Encoded Home Team: 14, Encoded Away Team: 17\n",
      "Pau FC win probability: 0.05\n",
      "St Etienne win probability: 0.38\n",
      "Draw probability: 0.57\n",
      "Encoded Home Team: 5, Encoded Away Team: 7\n",
      "Bastia win probability: 0.02\n",
      "Caen win probability: 0.44\n",
      "Draw probability: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.02, 0.44, 0.54)"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_match(home_team, away_team, best_model, df, label_encoder,scaler):\n",
    "     # Debugging: Check if the team names are in label_encoder's classes\n",
    "    if home_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Home team name '{home_team}' not recognized.\")\n",
    "    if away_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Away team name '{away_team}' not recognized.\")\n",
    "\n",
    "    # Transform team names\n",
    "    home_team_encoded = label_encoder.transform([home_team])[0]\n",
    "    away_team_encoded = label_encoder.transform([away_team])[0]\n",
    "\n",
    "    # Debugging: Print encoded values\n",
    "    print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "    # Prepare the match data with relevant features\n",
    "    match_data = {\n",
    "        'HomeTeam_encoded': label_encoder.transform([home_team])[0],\n",
    "        'AwayTeam_encoded': label_encoder.transform([away_team])[0],\n",
    "        'HomeTeamRecentForm': calculate_form_points(home_team, df)[0],\n",
    "        'AwayTeamRecentForm': calculate_form_points(away_team, df)[1],\n",
    "        'HomeTeamAvgGoals': df[df['HomeTeam'] == home_team]['FTHG'].mean(),\n",
    "        'AwayTeamAvgGoals': df[df['AwayTeam'] == away_team]['FTAG'].mean(),\n",
    "        'HomeTeamPoints': df[df['HomeTeam'] == home_team]['FTR_encoded'].sum() / df[df['HomeTeam'] == home_team]['FTR_encoded'].count(),\n",
    "        'AwayTeamPoints': df[df['AwayTeam'] == away_team]['FTR_encoded'].sum() / df[df['AwayTeam'] == away_team]['FTR_encoded'].count(),\n",
    "        'HomeGoalsScoredVariance': df[df['HomeTeam'] == home_team]['FTHG'].var(),\n",
    "        'AwayGoalsScoredVariance': df[df['AwayTeam'] == away_team]['FTAG'].var(),\n",
    "        'HomeGoalsScoredAvg_3': df[df['HomeTeam'] == home_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_3': df[df['AwayTeam'] == away_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_3': df[df['HomeTeam'] == home_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_3': df[df['AwayTeam'] == away_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsScoredAvg_5': df[df['HomeTeam'] == home_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_5': df[df['AwayTeam'] == away_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_5': df[df['HomeTeam'] == home_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_5': df[df['AwayTeam'] == away_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        \n",
    "        # Add other features as required by the model, calculated or retrieved as done during training\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    match_df = pd.DataFrame([match_data])\n",
    "    match_scaled = scaler.transform(match_df)\n",
    "    # Make predictions\n",
    "    home_team_win_prob = best_model.predict_proba(match_scaled)[0][0]\n",
    "    away_team_win_prob = best_model.predict_proba(match_scaled)[0][2]\n",
    "    draw_prob = best_model.predict_proba(match_scaled)[0][1]\n",
    "    # Print the results\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    \n",
    "    return home_team_win_prob, away_team_win_prob, draw_prob\n",
    "\n",
    "\n",
    "\n",
    "print('##########################')\n",
    "print('Today\\'s matches')\n",
    "\n",
    "predict_match('Amiens', 'Annecy', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Angers', 'Quevilly Rouen', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Bordeaux', 'Valenciennes', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Concarneau', 'Troyes', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Dunkerque', 'Ajaccio', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Guingamp', 'Rodez', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Laval', 'Paris FC', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Pau FC', 'St Etienne', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Bastia', 'Caen', best_model, df, label_encoder, scaler)\n",
    "\n",
    "# predict_match('Sheffield United', 'West Ham', best_model, df, label_encoder,scaler)\n",
    "# \n",
    "# predict_match('Bournemouth', 'Liverpool', best_model, df, label_encoder,scaler)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:41:19.708747900Z",
     "start_time": "2024-01-24T00:41:19.377129400Z"
    }
   },
   "id": "c6620460d2ef2cd2",
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # save the 3 models\n",
    "# import joblib\n",
    "# \n",
    "# # Save the model as a pickle file\n",
    "# joblib.dump(best_model, 'models/best_model.pkl')\n",
    "# # joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "# # joblib.dump(scaler, 'scaler.pkl')\n",
    "#     \n",
    "# # save the xgb model\n",
    "# import pickle\n",
    "# \n",
    "# # Save the model as a pickle file\n",
    "# pickle.dump(xgb_model, open('models/xgb_model.pkl', 'wb'))\n",
    "# # pickle.dump(label_encoder, open('label_encoder.pkl', 'wb'))\n",
    "# # pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
    "# \n",
    "# # save the catboost model\n",
    "# import pickle\n",
    "# \n",
    "# # Save the model as a pickle file\n",
    "# pickle.dump(catboost_model, open('models/catboost_model.pkl', 'wb'))\n",
    "# pickle.dump(label_encoder, open('models/label_encoder.pkl', 'wb'))\n",
    "# pickle.dump(scaler, open('models/scaler.pkl', 'wb'))\n",
    "# \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:41:19.714748400Z",
     "start_time": "2024-01-24T00:41:19.684231100Z"
    }
   },
   "id": "d715b9c2999b356c",
   "execution_count": 190
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T00:41:19.715747600Z",
     "start_time": "2024-01-24T00:41:19.689048900Z"
    }
   },
   "id": "b4555e5f77028032",
   "execution_count": 190
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
