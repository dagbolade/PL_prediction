{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Championship 2023-2024 Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2043b1fe4e1c4d13"
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.216497700Z",
     "start_time": "2024-01-20T05:33:52.045391200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Div        Date   Time    HomeTeam        AwayTeam  FTHG  FTAG FTR  HTHG  \\\n185  F2  19/12/2023  19:45   Dunkerque        Bordeaux     0     2   A     0   \n186  F2  19/12/2023  19:45       Laval         Auxerre     1     3   A     1   \n187  F2  19/12/2023  19:45    Paris FC  Quevilly Rouen     2     2   D     1   \n188  F2  19/12/2023  19:45      Pau FC          Troyes     1     1   D     0   \n189  F2  19/12/2023  19:45  St Etienne          Bastia     3     2   H     2   \n\n     HTAG  ... AvgC<2.5  AHCh  B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  \\\n185     1  ...     1.93  0.50      1.95      1.90   1.96   1.93     1.96   \n186     1  ...     1.69  0.50      1.80      2.05   1.83   2.07     1.83   \n187     1  ...     1.71 -0.25      2.00      1.85   2.04   1.85     2.05   \n188     0  ...     2.09 -0.25      1.85      2.00   1.86   2.03     1.91   \n189     0  ...     1.73 -0.50      1.80      2.05   1.81   2.07     1.88   \n\n     MaxCAHA  AvgCAHH  AvgCAHA  \n185     2.00     1.87     1.92  \n186     2.11     1.78     2.00  \n187     1.89     1.95     1.84  \n188     2.14     1.80     2.02  \n189     2.08     1.81     1.97  \n\n[5 rows x 105 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>...</th>\n      <th>AvgC&lt;2.5</th>\n      <th>AHCh</th>\n      <th>B365CAHH</th>\n      <th>B365CAHA</th>\n      <th>PCAHH</th>\n      <th>PCAHA</th>\n      <th>MaxCAHH</th>\n      <th>MaxCAHA</th>\n      <th>AvgCAHH</th>\n      <th>AvgCAHA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>185</th>\n      <td>F2</td>\n      <td>19/12/2023</td>\n      <td>19:45</td>\n      <td>Dunkerque</td>\n      <td>Bordeaux</td>\n      <td>0</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.93</td>\n      <td>0.50</td>\n      <td>1.95</td>\n      <td>1.90</td>\n      <td>1.96</td>\n      <td>1.93</td>\n      <td>1.96</td>\n      <td>2.00</td>\n      <td>1.87</td>\n      <td>1.92</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>F2</td>\n      <td>19/12/2023</td>\n      <td>19:45</td>\n      <td>Laval</td>\n      <td>Auxerre</td>\n      <td>1</td>\n      <td>3</td>\n      <td>A</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.69</td>\n      <td>0.50</td>\n      <td>1.80</td>\n      <td>2.05</td>\n      <td>1.83</td>\n      <td>2.07</td>\n      <td>1.83</td>\n      <td>2.11</td>\n      <td>1.78</td>\n      <td>2.00</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>F2</td>\n      <td>19/12/2023</td>\n      <td>19:45</td>\n      <td>Paris FC</td>\n      <td>Quevilly Rouen</td>\n      <td>2</td>\n      <td>2</td>\n      <td>D</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.71</td>\n      <td>-0.25</td>\n      <td>2.00</td>\n      <td>1.85</td>\n      <td>2.04</td>\n      <td>1.85</td>\n      <td>2.05</td>\n      <td>1.89</td>\n      <td>1.95</td>\n      <td>1.84</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>F2</td>\n      <td>19/12/2023</td>\n      <td>19:45</td>\n      <td>Pau FC</td>\n      <td>Troyes</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2.09</td>\n      <td>-0.25</td>\n      <td>1.85</td>\n      <td>2.00</td>\n      <td>1.86</td>\n      <td>2.03</td>\n      <td>1.91</td>\n      <td>2.14</td>\n      <td>1.80</td>\n      <td>2.02</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>F2</td>\n      <td>19/12/2023</td>\n      <td>19:45</td>\n      <td>St Etienne</td>\n      <td>Bastia</td>\n      <td>3</td>\n      <td>2</td>\n      <td>H</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.73</td>\n      <td>-0.50</td>\n      <td>1.80</td>\n      <td>2.05</td>\n      <td>1.81</td>\n      <td>2.07</td>\n      <td>1.88</td>\n      <td>2.08</td>\n      <td>1.81</td>\n      <td>1.97</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 105 columns</p>\n</div>"
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('F2.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "outputs": [],
   "source": [
    "## Data Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.220482100Z",
     "start_time": "2024-01-20T05:33:52.180819Z"
    }
   },
   "id": "c27a39651ea01908"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(Div         0\n Date        0\n Time        0\n HomeTeam    0\n AwayTeam    0\n            ..\n PCAHA       0\n MaxCAHH     0\n MaxCAHA     0\n AvgCAHH     0\n AvgCAHA     0\n Length: 105, dtype: int64,\n 0)"
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# steps:\n",
    "# 1. Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# 2. Check for duplicates\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "# Display the results of the checks\n",
    "missing_values, duplicate_rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.271156700Z",
     "start_time": "2024-01-20T05:33:52.226492700Z"
    }
   },
   "id": "594bb92f2a11837b",
   "execution_count": 617
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "outputs": [
    {
     "data": {
      "text/plain": "(Div         0\n Date        0\n Time        0\n HomeTeam    0\n AwayTeam    0\n            ..\n PCAHA       0\n MaxCAHH     0\n MaxCAHA     0\n AvgCAHH     0\n AvgCAHA     0\n Length: 105, dtype: int64,\n FTR\n H    74\n A    59\n D    57\n Name: count, dtype: int64)"
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Checking the balance of the target variable 'FTR'\n",
    "target_distribution = df['FTR'].value_counts()\n",
    "\n",
    "# drop the div column\n",
    "df.drop('Div', axis=1, inplace=True)\n",
    "df.drop('Time', axis=1, inplace=True)\n",
    "\n",
    "missing_values, target_distribution\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.371923800Z",
     "start_time": "2024-01-20T05:33:52.277158700Z"
    }
   },
   "id": "598e531010defdf9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# covert date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.472238600Z",
     "start_time": "2024-01-20T05:33:52.301484700Z"
    }
   },
   "id": "e670089d22767e09",
   "execution_count": 619
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature engineering\n",
    "\n",
    "### steps:\n",
    "* Encode Team Names: Use label encoding for 'HomeTeam' and 'AwayTeam'. This will convert team names into numeric values, making them usable for the model.\n",
    "\n",
    "* Recent Form: Calculate the recent form for each team based on the last 5 matches. We'll use the 'FTR' column to determine wins (W), losses (L), and draws (D). This feature will provide insight into the current performance of the teams.\n",
    "\n",
    "* Average Goals per Game: Compute the average goals scored per game for both home and away teams. This feature helps understand the offensive strength of the teams.\n",
    "\n",
    "* Team Points: Calculate the total points accumulated by each team so far in the season. Points are awarded based on wins (3 points), draws (1 point), and losses (0 points).\n",
    "\n",
    "* Head-to-Head Statistics: Analyze the outcomes of matches between the same pairs of teams earlier in the season.\n",
    "\n",
    "* Other Statistical Features: Depending on the data available, we can include additional features like average possession, number of shots on target, defensive strength, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d8eb8645de65cd7"
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "outputs": [],
   "source": [
    "# Reset the index of the DataFrame (if necessary)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rolling averages for goals\n",
    "window_sizes = [3, 5]\n",
    "for window in window_sizes:\n",
    "    df[f'HomeGoalsScoredAvg_{window}'] = df.groupby('HomeTeam')['FTHG'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "    df[f'AwayGoalsScoredAvg_{window}'] = df.groupby('AwayTeam')['FTAG'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "    df[f'HomeGoalsConcededAvg_{window}'] = df.groupby('HomeTeam')['FTAG'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "    df[f'AwayGoalsConcededAvg_{window}'] = df.groupby('AwayTeam')['FTHG'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.590371500Z",
     "start_time": "2024-01-20T05:33:52.477237400Z"
    }
   },
   "id": "555cad6dc030dab3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Variance in team performance\n",
    "df['HomeGoalsScoredVariance'] = df.groupby('HomeTeam')['FTHG'].transform(lambda x: x.rolling(5, min_periods=1).var())\n",
    "df['AwayGoalsScoredVariance'] = df.groupby('AwayTeam')['FTAG'].transform(lambda x: x.rolling(5, min_periods=1).var())\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.593371600Z",
     "start_time": "2024-01-20T05:33:52.546942200Z"
    }
   },
   "id": "b3bf9df58be1de92",
   "execution_count": 621
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Home Team: 17, Encoded Away Team: 12\n",
      "['Ajaccio' 'Amiens' 'Angers' 'Annecy' 'Auxerre' 'Bastia' 'Bordeaux' 'Caen'\n",
      " 'Concarneau' 'Dunkerque' 'Grenoble' 'Guingamp' 'Laval' 'Paris FC'\n",
      " 'Pau FC' 'Quevilly Rouen' 'Rodez' 'St Etienne' 'Troyes' 'Valenciennes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Combine all unique team names from both HomeTeam and AwayTeam columns\n",
    "all_teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
    "\n",
    "# Fit the LabelEncoder with all unique team names\n",
    "label_encoder.fit(all_teams)\n",
    "\n",
    "# Transform both HomeTeam and AwayTeam using the fitted LabelEncoder\n",
    "df['HomeTeam_encoded'] = label_encoder.transform(df['HomeTeam'])\n",
    "df['AwayTeam_encoded'] = label_encoder.transform(df['AwayTeam'])\n",
    "\n",
    "# Now you can transform individual team names\n",
    "home_team_encoded = label_encoder.transform(['St Etienne'])[0]\n",
    "away_team_encoded = label_encoder.transform(['Laval'])[0]\n",
    "\n",
    "# Debugging: Print encoded values\n",
    "print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "print(label_encoder.classes_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.729573200Z",
     "start_time": "2024-01-20T05:33:52.602426800Z"
    }
   },
   "id": "2b1a8cf45ea677d9",
   "execution_count": 622
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          Date    HomeTeam        AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n185 2023-12-19   Dunkerque        Bordeaux     0     2   A     0     1   A   \n186 2023-12-19       Laval         Auxerre     1     3   A     1     1   D   \n187 2023-12-19    Paris FC  Quevilly Rouen     2     2   D     1     1   D   \n188 2023-12-19      Pau FC          Troyes     1     1   D     0     0   D   \n189 2023-12-19  St Etienne          Bastia     3     2   H     2     0   H   \n\n     HS  ...  HomeGoalsConcededAvg_3  AwayGoalsConcededAvg_3  \\\n185  14  ...                3.000000                1.333333   \n186   5  ...                1.666667                0.666667   \n187  10  ...                1.333333                1.666667   \n188  19  ...                1.000000                0.666667   \n189  12  ...                2.333333                1.333333   \n\n     HomeGoalsScoredAvg_5  AwayGoalsScoredAvg_5  HomeGoalsConcededAvg_5  \\\n185                   0.2                   1.4                     2.6   \n186                   0.6                   1.4                     1.8   \n187                   1.6                   1.8                     1.2   \n188                   2.4                   1.0                     1.8   \n189                   1.4                   1.6                     1.6   \n\n     AwayGoalsConcededAvg_5  HomeGoalsScoredVariance  AwayGoalsScoredVariance  \\\n185                     1.8                      0.2                      0.8   \n186                     1.0                      0.3                      1.3   \n187                     2.0                      0.3                      1.2   \n188                     1.0                      1.8                      0.5   \n189                     1.2                      1.3                      4.3   \n\n     HomeTeam_encoded  AwayTeam_encoded  \n185                 9                 6  \n186                12                 4  \n187                13                15  \n188                14                18  \n189                17                 5  \n\n[5 rows x 115 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>HTR</th>\n      <th>HS</th>\n      <th>...</th>\n      <th>HomeGoalsConcededAvg_3</th>\n      <th>AwayGoalsConcededAvg_3</th>\n      <th>HomeGoalsScoredAvg_5</th>\n      <th>AwayGoalsScoredAvg_5</th>\n      <th>HomeGoalsConcededAvg_5</th>\n      <th>AwayGoalsConcededAvg_5</th>\n      <th>HomeGoalsScoredVariance</th>\n      <th>AwayGoalsScoredVariance</th>\n      <th>HomeTeam_encoded</th>\n      <th>AwayTeam_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>185</th>\n      <td>2023-12-19</td>\n      <td>Dunkerque</td>\n      <td>Bordeaux</td>\n      <td>0</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>14</td>\n      <td>...</td>\n      <td>3.000000</td>\n      <td>1.333333</td>\n      <td>0.2</td>\n      <td>1.4</td>\n      <td>2.6</td>\n      <td>1.8</td>\n      <td>0.2</td>\n      <td>0.8</td>\n      <td>9</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>2023-12-19</td>\n      <td>Laval</td>\n      <td>Auxerre</td>\n      <td>1</td>\n      <td>3</td>\n      <td>A</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1.666667</td>\n      <td>0.666667</td>\n      <td>0.6</td>\n      <td>1.4</td>\n      <td>1.8</td>\n      <td>1.0</td>\n      <td>0.3</td>\n      <td>1.3</td>\n      <td>12</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>2023-12-19</td>\n      <td>Paris FC</td>\n      <td>Quevilly Rouen</td>\n      <td>2</td>\n      <td>2</td>\n      <td>D</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>10</td>\n      <td>...</td>\n      <td>1.333333</td>\n      <td>1.666667</td>\n      <td>1.6</td>\n      <td>1.8</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>0.3</td>\n      <td>1.2</td>\n      <td>13</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>2023-12-19</td>\n      <td>Pau FC</td>\n      <td>Troyes</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>0</td>\n      <td>0</td>\n      <td>D</td>\n      <td>19</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>2.4</td>\n      <td>1.0</td>\n      <td>1.8</td>\n      <td>1.0</td>\n      <td>1.8</td>\n      <td>0.5</td>\n      <td>14</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>2023-12-19</td>\n      <td>St Etienne</td>\n      <td>Bastia</td>\n      <td>3</td>\n      <td>2</td>\n      <td>H</td>\n      <td>2</td>\n      <td>0</td>\n      <td>H</td>\n      <td>12</td>\n      <td>...</td>\n      <td>2.333333</td>\n      <td>1.333333</td>\n      <td>1.4</td>\n      <td>1.6</td>\n      <td>1.6</td>\n      <td>1.2</td>\n      <td>1.3</td>\n      <td>4.3</td>\n      <td>17</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 115 columns</p>\n</div>"
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.828439800Z",
     "start_time": "2024-01-20T05:33:52.689189300Z"
    }
   },
   "id": "68ab9522885d1ebc",
   "execution_count": 623
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Encoding the target variable 'FTR'\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variable using label_encoder_y\n",
    "df['FTR_encoded'] = label_encoder.fit_transform(df['FTR'])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.868789900Z",
     "start_time": "2024-01-20T05:33:52.797294500Z"
    }
   },
   "id": "fdeeda8cbb73755a",
   "execution_count": 624
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Average points per game\n",
    "df['HomeTeamPoints'] = df.groupby('HomeTeam')['FTR_encoded'].transform(lambda x: x.expanding().sum().shift(1)) / df.groupby('HomeTeam')['FTR_encoded'].transform(lambda x: x.expanding().count().shift(1))\n",
    "df['AwayTeamPoints'] = df.groupby('AwayTeam')['FTR_encoded'].transform(lambda x: x.expanding().sum().shift(1)) / df.groupby('AwayTeam')['FTR_encoded'].transform(lambda x: x.expanding().count().shift(1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:52.960174100Z",
     "start_time": "2024-01-20T05:33:52.840111100Z"
    }
   },
   "id": "a5308beebd3622e1",
   "execution_count": 625
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Average goals per game\n",
    "df['HomeTeamAvgGoals'] = df.groupby('HomeTeam')['FTHG'].transform(lambda x: x.expanding().mean().shift(1)) # Average goals scored by the home team\n",
    "df['AwayTeamAvgGoals'] = df.groupby('AwayTeam')['FTAG'].transform(lambda x: x.expanding().mean().shift(1)) # Average goals scored by the away team\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:53.058647400Z",
     "start_time": "2024-01-20T05:33:52.920529700Z"
    }
   },
   "id": "a9226672bfa2d435",
   "execution_count": 626
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# recent form\n",
    "def calculate_form_points(team, df):\n",
    "    # Get the last 5 matches of the home and away teams\n",
    "    home_matches = df[df['HomeTeam'] == team].tail(5)\n",
    "    away_matches = df[df['AwayTeam'] == team].tail(5)\n",
    "\n",
    "    # Calculate the points obtained in the last 5 matches\n",
    "    home_points = home_matches['FTR_encoded'].sum()\n",
    "    away_points = away_matches['FTR_encoded'].sum()\n",
    "\n",
    "    # Calculate the average points obtained\n",
    "    home_avg_points = home_points / 15\n",
    "    away_avg_points = away_points / 15\n",
    "\n",
    "    # Return the average points\n",
    "    return home_avg_points, away_avg_points\n",
    "\n",
    "# Calculate the average points obtained by each team in the last 5 matches\n",
    "df['HomeTeamRecentForm'], df['AwayTeamRecentForm'] = zip(*df['HomeTeam'].apply(lambda x: calculate_form_points(x, df)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:53.258434700Z",
     "start_time": "2024-01-20T05:33:53.003174400Z"
    }
   },
   "id": "7433bf2c3ef3a5e7",
   "execution_count": 627
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b8611cb69bd65f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recent Form"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f21cce905c91424"
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert 'Date' to datetime and extract useful features\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek  # 0: Monday, 6: Sunday\n",
    "df['IsWeekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)  # 1 for weekend, 0 for weekdays\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:53.259434900Z",
     "start_time": "2024-01-20T05:33:53.248939100Z"
    }
   },
   "id": "e80b6e05d39f4181"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:53.296559700Z",
     "start_time": "2024-01-20T05:33:53.255092300Z"
    }
   },
   "id": "3df868f314128140",
   "execution_count": 628
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#select relevant columns or features and the target\n",
    "features = [\n",
    "    'HomeTeam_encoded', 'AwayTeam_encoded', 'HomeTeamRecentForm', 'AwayTeamRecentForm', \n",
    "    'HomeTeamAvgGoals', 'AwayTeamAvgGoals', 'HomeTeamPoints', 'AwayTeamPoints', 'HomeGoalsScoredVariance', 'AwayGoalsScoredVariance', 'HomeGoalsScoredAvg_3', 'AwayGoalsScoredAvg_3', 'HomeGoalsConcededAvg_3', 'AwayGoalsConcededAvg_3', 'HomeGoalsScoredAvg_5', 'AwayGoalsScoredAvg_5', 'HomeGoalsConcededAvg_5', 'AwayGoalsConcededAvg_5',\n",
    "]\n",
    "\n",
    "target = 'FTR_encoded'\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Previewing the processed features\n",
    "X_train.head(7), y_train.head(7)\n",
    "\n",
    "# encoding the categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variable using label_encoder_y\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:53.299554100Z",
     "start_time": "2024-01-20T05:33:53.263443Z"
    }
   },
   "id": "5c1fefe366e02665",
   "execution_count": 629
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both the training and testing sets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:33:53.384973Z",
     "start_time": "2024-01-20T05:33:53.304672500Z"
    }
   },
   "id": "474e0ec0b8de5c52",
   "execution_count": 630
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Team Points"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1ad0e76308763b7"
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 152, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score -1.262680\n",
      "[LightGBM] [Info] Start training from score -1.053589\n",
      "[LightGBM] [Info] Start training from score -0.998529\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x21c6f78ae50>"
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize the models\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "lgbm_model = LGBMClassifier(random_state=42)   \n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=False)\n",
    "\n",
    "# Train the models\n",
    "#rf_model.fit(X_train, y_train_encoded)\n",
    "xgb_model.fit(X_train_scaled, y_train_encoded)\n",
    "lgbm_model.fit(X_train_scaled, y_train_encoded)\n",
    "catboost_model.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:34:00.940831400Z",
     "start_time": "2024-01-20T05:33:53.388983600Z"
    }
   },
   "id": "8b40589ac3bdd675"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Metrics\n",
      "Accuracy: 0.23684210526315788\n",
      "Precision: 0.4259259259259259\n",
      "Recall: 0.17592592592592593\n",
      "F1 Score: 0.24555555555555555\n",
      "\n",
      "\n",
      "LightGBM Model Metrics\n",
      "Accuracy: 0.21052631578947367\n",
      "Precision: 0.4666666666666666\n",
      "Recall: 0.2800925925925926\n",
      "F1 Score: 0.21514161220043573\n",
      "\n",
      "\n",
      "CatBoost Model Metrics\n",
      "Accuracy: 0.2631578947368421\n",
      "Precision: 0.4473015873015873\n",
      "Recall: 0.32175925925925924\n",
      "F1 Score: 0.2718224221222722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#evaluate the models using the metrics\n",
    "models = [ xgb_model, lgbm_model, catboost_model]\n",
    "model_names = [ 'XGBoost', 'LightGBM', 'CatBoost']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    print(f\"{name} Model Metrics\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:34:00.956106600Z",
     "start_time": "2024-01-20T05:34:00.925830Z"
    }
   },
   "id": "70ee9938150d56d0",
   "execution_count": 632
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          Date    HomeTeam        AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n185 2023-12-19   Dunkerque        Bordeaux     0     2   A     0     1   A   \n186 2023-12-19       Laval         Auxerre     1     3   A     1     1   D   \n187 2023-12-19    Paris FC  Quevilly Rouen     2     2   D     1     1   D   \n188 2023-12-19      Pau FC          Troyes     1     1   D     0     0   D   \n189 2023-12-19  St Etienne          Bastia     3     2   H     2     0   H   \n\n     HS  ...  AwayTeam_encoded  FTR_encoded  HomeTeamPoints  AwayTeamPoints  \\\n185  14  ...                 6            0        0.222222        1.333333   \n186   5  ...                 4            0        1.333333        0.555556   \n187  10  ...                15            1        1.000000        1.333333   \n188  19  ...                18            1        1.444444        1.222222   \n189  12  ...                 5            2        0.888889        1.444444   \n\n     HomeTeamAvgGoals  AwayTeamAvgGoals  HomeTeamRecentForm  \\\n185          0.444444          0.777778            0.000000   \n186          1.000000          2.000000            0.133333   \n187          1.333333          1.333333            0.400000   \n188          2.111111          1.000000            0.466667   \n189          0.888889          0.777778            0.266667   \n\n     AwayTeamRecentForm  DayOfWeek  IsWeekend  \n185            0.333333          1          0  \n186            0.200000          1          0  \n187            0.066667          1          0  \n188            0.266667          1          0  \n189            0.333333          1          0  \n\n[5 rows x 124 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>HomeTeam</th>\n      <th>AwayTeam</th>\n      <th>FTHG</th>\n      <th>FTAG</th>\n      <th>FTR</th>\n      <th>HTHG</th>\n      <th>HTAG</th>\n      <th>HTR</th>\n      <th>HS</th>\n      <th>...</th>\n      <th>AwayTeam_encoded</th>\n      <th>FTR_encoded</th>\n      <th>HomeTeamPoints</th>\n      <th>AwayTeamPoints</th>\n      <th>HomeTeamAvgGoals</th>\n      <th>AwayTeamAvgGoals</th>\n      <th>HomeTeamRecentForm</th>\n      <th>AwayTeamRecentForm</th>\n      <th>DayOfWeek</th>\n      <th>IsWeekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>185</th>\n      <td>2023-12-19</td>\n      <td>Dunkerque</td>\n      <td>Bordeaux</td>\n      <td>0</td>\n      <td>2</td>\n      <td>A</td>\n      <td>0</td>\n      <td>1</td>\n      <td>A</td>\n      <td>14</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.222222</td>\n      <td>1.333333</td>\n      <td>0.444444</td>\n      <td>0.777778</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>2023-12-19</td>\n      <td>Laval</td>\n      <td>Auxerre</td>\n      <td>1</td>\n      <td>3</td>\n      <td>A</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>5</td>\n      <td>...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.333333</td>\n      <td>0.555556</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>0.133333</td>\n      <td>0.200000</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>2023-12-19</td>\n      <td>Paris FC</td>\n      <td>Quevilly Rouen</td>\n      <td>2</td>\n      <td>2</td>\n      <td>D</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>10</td>\n      <td>...</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>1.333333</td>\n      <td>1.333333</td>\n      <td>1.333333</td>\n      <td>0.400000</td>\n      <td>0.066667</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>2023-12-19</td>\n      <td>Pau FC</td>\n      <td>Troyes</td>\n      <td>1</td>\n      <td>1</td>\n      <td>D</td>\n      <td>0</td>\n      <td>0</td>\n      <td>D</td>\n      <td>19</td>\n      <td>...</td>\n      <td>18</td>\n      <td>1</td>\n      <td>1.444444</td>\n      <td>1.222222</td>\n      <td>2.111111</td>\n      <td>1.000000</td>\n      <td>0.466667</td>\n      <td>0.266667</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>2023-12-19</td>\n      <td>St Etienne</td>\n      <td>Bastia</td>\n      <td>3</td>\n      <td>2</td>\n      <td>H</td>\n      <td>2</td>\n      <td>0</td>\n      <td>H</td>\n      <td>12</td>\n      <td>...</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0.888889</td>\n      <td>1.444444</td>\n      <td>0.888889</td>\n      <td>0.777778</td>\n      <td>0.266667</td>\n      <td>0.333333</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 124 columns</p>\n</div>"
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:34:00.991174800Z",
     "start_time": "2024-01-20T05:34:00.955108300Z"
    }
   },
   "id": "e367025c878a3474",
   "execution_count": 633
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Home Team: 17, Encoded Away Team: 12\n",
      "['Ajaccio' 'Amiens' 'Angers' 'Annecy' 'Auxerre' 'Bastia' 'Bordeaux' 'Caen'\n",
      " 'Concarneau' 'Dunkerque' 'Grenoble' 'Guingamp' 'Laval' 'Paris FC'\n",
      " 'Pau FC' 'Quevilly Rouen' 'Rodez' 'St Etienne' 'Troyes' 'Valenciennes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Combine all unique team names from both HomeTeam and AwayTeam columns\n",
    "all_teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
    "\n",
    "# Fit the LabelEncoder with all unique team names\n",
    "label_encoder.fit(all_teams)\n",
    "\n",
    "# Transform both HomeTeam and AwayTeam using the fitted LabelEncoder\n",
    "df['HomeTeam_encoded'] = label_encoder.transform(df['HomeTeam'])\n",
    "df['AwayTeam_encoded'] = label_encoder.transform(df['AwayTeam'])\n",
    "\n",
    "# Now you can transform individual team names\n",
    "home_team_encoded = label_encoder.transform(['St Etienne'])[0]\n",
    "away_team_encoded = label_encoder.transform(['Laval'])[0]\n",
    "\n",
    "# Debugging: Print encoded values\n",
    "print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "print(label_encoder.classes_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:34:01.041191300Z",
     "start_time": "2024-01-20T05:34:00.979044800Z"
    }
   },
   "id": "46326b9866c00cf4",
   "execution_count": 634
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Today's matches\n",
      "Encoded Home Team: 17, Encoded Away Team: 12\n",
      "St Etienne win probability: 0.1919000893831253\n",
      "Draw probability: 0.7436269521713257\n",
      "Laval win probability: 0.06447300314903259\n",
      "Encoded Home Team: 7, Encoded Away Team: 8\n",
      "Caen win probability: 0.45467352867126465\n",
      "Draw probability: 0.4960976839065552\n",
      "Concarneau win probability: 0.04922875761985779\n",
      "Encoded Home Team: 10, Encoded Away Team: 9\n",
      "Grenoble win probability: 0.3971242606639862\n",
      "Draw probability: 0.552302360534668\n",
      "Dunkerque win probability: 0.050573356449604034\n",
      "Encoded Home Team: 13, Encoded Away Team: 3\n",
      "Paris FC win probability: 0.3224872052669525\n",
      "Draw probability: 0.5994745492935181\n",
      "Annecy win probability: 0.07803826034069061\n",
      "Encoded Home Team: 15, Encoded Away Team: 11\n",
      "Quevilly Rouen win probability: 0.4085828363895416\n",
      "Draw probability: 0.5393984317779541\n",
      "Guingamp win probability: 0.052018746733665466\n",
      "Encoded Home Team: 16, Encoded Away Team: 14\n",
      "Rodez win probability: 0.21343238651752472\n",
      "Draw probability: 0.7361482977867126\n",
      "Pau FC win probability: 0.05041932687163353\n",
      "Encoded Home Team: 5, Encoded Away Team: 2\n",
      "Bastia win probability: 0.19037050008773804\n",
      "Draw probability: 0.7349735498428345\n",
      "Angers win probability: 0.07465595752000809\n",
      "Encoded Home Team: 18, Encoded Away Team: 0\n",
      "Troyes win probability: 0.5120545625686646\n",
      "Draw probability: 0.280146062374115\n",
      "Ajaccio win probability: 0.20779940485954285\n",
      "Encoded Home Team: 19, Encoded Away Team: 1\n",
      "Valenciennes win probability: 0.4008001983165741\n",
      "Draw probability: 0.5689399242401123\n",
      "Amiens win probability: 0.03025989979505539\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.4008002, 0.5689399, 0.0302599)"
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_match(home_team, away_team, xgb_model, df, label_encoder):\n",
    "     # Debugging: Check if the team names are in label_encoder's classes\n",
    "    if home_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Home team name '{home_team}' not recognized.\")\n",
    "    if away_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Away team name '{away_team}' not recognized.\")\n",
    "\n",
    "    # Transform team names\n",
    "    home_team_encoded = label_encoder.transform([home_team])[0]\n",
    "    away_team_encoded = label_encoder.transform([away_team])[0]\n",
    "\n",
    "    # Debugging: Print encoded values\n",
    "    print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "    # Prepare the match data with relevant features\n",
    "    match_data = {\n",
    "        'HomeTeam_encoded': label_encoder.transform([home_team])[0],\n",
    "        'AwayTeam_encoded': label_encoder.transform([away_team])[0],\n",
    "        'HomeTeamRecentForm': calculate_form_points(home_team, df)[0],\n",
    "        'AwayTeamRecentForm': calculate_form_points(away_team, df)[1],\n",
    "        'HomeTeamAvgGoals': df[df['HomeTeam'] == home_team]['FTHG'].mean(),\n",
    "        'AwayTeamAvgGoals': df[df['AwayTeam'] == away_team]['FTAG'].mean(),\n",
    "        'HomeTeamPoints': df[df['HomeTeam'] == home_team]['FTR_encoded'].sum() / df[df['HomeTeam'] == home_team]['FTR_encoded'].count(),\n",
    "        'AwayTeamPoints': df[df['AwayTeam'] == away_team]['FTR_encoded'].sum() / df[df['AwayTeam'] == away_team]['FTR_encoded'].count(),\n",
    "        'HomeGoalsScoredVariance': df[df['HomeTeam'] == home_team]['FTHG'].var(),\n",
    "        'AwayGoalsScoredVariance': df[df['AwayTeam'] == away_team]['FTAG'].var(),\n",
    "        'HomeGoalsScoredAvg_3': df[df['HomeTeam'] == home_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_3': df[df['AwayTeam'] == away_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_3': df[df['HomeTeam'] == home_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_3': df[df['AwayTeam'] == away_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsScoredAvg_5': df[df['HomeTeam'] == home_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_5': df[df['AwayTeam'] == away_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_5': df[df['HomeTeam'] == home_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_5': df[df['AwayTeam'] == away_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        \n",
    "        # Add other features as required by the model, calculated or retrieved as done during training\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    match_df = pd.DataFrame([match_data])\n",
    "\n",
    "    # Make predictions\n",
    "    probabilities = xgb_model.predict_proba(match_df)[0]\n",
    "    home_team_win_prob = probabilities[0]\n",
    "    draw_prob = probabilities[1]\n",
    "    away_team_win_prob = probabilities[2]\n",
    "\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "\n",
    "    return home_team_win_prob, draw_prob, away_team_win_prob\n",
    "\n",
    "\n",
    "\n",
    "print('##########################')\n",
    "print('Today\\'s matches')\n",
    "\n",
    "predict_match('St Etienne', 'Laval', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Caen', 'Concarneau', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Grenoble', 'Dunkerque', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Paris FC', 'Annecy', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Quevilly Rouen', 'Guingamp', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Rodez', 'Pau FC', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Bastia', 'Angers', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Troyes', 'Ajaccio', xgb_model, df, label_encoder)\n",
    "\n",
    "predict_match('Valenciennes', 'Amiens', xgb_model, df, label_encoder)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:37:38.753015Z",
     "start_time": "2024-01-20T05:37:38.608338400Z"
    }
   },
   "id": "fc7f5a44c0b70d65"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Today's matches\n",
      "Encoded Home Team: 17, Encoded Away Team: 12\n",
      "St Etienne win probability: 0.41733230137147237\n",
      "Draw probability: 0.49051421643205484\n",
      "Laval win probability: 0.09215348219647271\n",
      "Encoded Home Team: 7, Encoded Away Team: 8\n",
      "Caen win probability: 0.4122002811732149\n",
      "Draw probability: 0.4891236305135153\n",
      "Concarneau win probability: 0.09867608831326978\n",
      "Encoded Home Team: 10, Encoded Away Team: 9\n",
      "Grenoble win probability: 0.4364251477504607\n",
      "Draw probability: 0.4943091487330067\n",
      "Dunkerque win probability: 0.06926570351653248\n",
      "Encoded Home Team: 13, Encoded Away Team: 3\n",
      "Paris FC win probability: 0.39555612827061304\n",
      "Draw probability: 0.47173367314245157\n",
      "Annecy win probability: 0.13271019858693536\n",
      "Encoded Home Team: 15, Encoded Away Team: 11\n",
      "Quevilly Rouen win probability: 0.42521677663137725\n",
      "Draw probability: 0.4772683935172214\n",
      "Guingamp win probability: 0.09751482985140134\n",
      "Encoded Home Team: 16, Encoded Away Team: 14\n",
      "Rodez win probability: 0.3942365863150441\n",
      "Draw probability: 0.5057752785420051\n",
      "Pau FC win probability: 0.09998813514295073\n",
      "Encoded Home Team: 5, Encoded Away Team: 2\n",
      "Bastia win probability: 0.3738998499198539\n",
      "Draw probability: 0.5067885673157707\n",
      "Angers win probability: 0.11931158276437535\n",
      "Encoded Home Team: 18, Encoded Away Team: 0\n",
      "Troyes win probability: 0.4986981738644155\n",
      "Draw probability: 0.40627495761846943\n",
      "Ajaccio win probability: 0.09502686851711512\n",
      "Encoded Home Team: 19, Encoded Away Team: 1\n",
      "Valenciennes win probability: 0.305109550284156\n",
      "Draw probability: 0.531444658407798\n",
      "Amiens win probability: 0.16344579130804612\n",
      "Encoded Home Team: 4, Encoded Away Team: 6\n",
      "Auxerre win probability: 0.3714788108792658\n",
      "Draw probability: 0.522258408504998\n",
      "Bordeaux win probability: 0.10626278061573607\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.3714788108792658, 0.522258408504998, 0.10626278061573607)"
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_match(home_team, away_team, catboost_model, df, label_encoder):\n",
    "     # Debugging: Check if the team names are in label_encoder's classes\n",
    "    if home_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Home team name '{home_team}' not recognized.\")\n",
    "    if away_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Away team name '{away_team}' not recognized.\")\n",
    "\n",
    "    # Transform team names\n",
    "    home_team_encoded = label_encoder.transform([home_team])[0]\n",
    "    away_team_encoded = label_encoder.transform([away_team])[0]\n",
    "\n",
    "    # Debugging: Print encoded values\n",
    "    print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "    # Prepare the match data with relevant features\n",
    "    match_data = {\n",
    "        'HomeTeam_encoded': label_encoder.transform([home_team])[0],\n",
    "        'AwayTeam_encoded': label_encoder.transform([away_team])[0],\n",
    "        'HomeTeamRecentForm': calculate_form_points(home_team, df)[0],\n",
    "        'AwayTeamRecentForm': calculate_form_points(away_team, df)[1],\n",
    "        'HomeTeamAvgGoals': df[df['HomeTeam'] == home_team]['FTHG'].mean(),\n",
    "        'AwayTeamAvgGoals': df[df['AwayTeam'] == away_team]['FTAG'].mean(),\n",
    "        'HomeTeamPoints': df[df['HomeTeam'] == home_team]['FTR_encoded'].sum() / df[df['HomeTeam'] == home_team]['FTR_encoded'].count(),\n",
    "        'AwayTeamPoints': df[df['AwayTeam'] == away_team]['FTR_encoded'].sum() / df[df['AwayTeam'] == away_team]['FTR_encoded'].count(),\n",
    "        'HomeGoalsScoredVariance': df[df['HomeTeam'] == home_team]['FTHG'].var(),\n",
    "        'AwayGoalsScoredVariance': df[df['AwayTeam'] == away_team]['FTAG'].var(),\n",
    "        'HomeGoalsScoredAvg_3': df[df['HomeTeam'] == home_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_3': df[df['AwayTeam'] == away_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_3': df[df['HomeTeam'] == home_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_3': df[df['AwayTeam'] == away_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsScoredAvg_5': df[df['HomeTeam'] == home_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_5': df[df['AwayTeam'] == away_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_5': df[df['HomeTeam'] == home_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_5': df[df['AwayTeam'] == away_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        \n",
    "        # Add other features as required by the model, calculated or retrieved as done during training\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    match_df = pd.DataFrame([match_data])\n",
    "\n",
    "    # Make predictions\n",
    "    probabilities = catboost_model.predict_proba(match_df)[0]\n",
    "    home_team_win_prob = probabilities[0]\n",
    "    draw_prob = probabilities[1]\n",
    "    away_team_win_prob = probabilities[2]\n",
    "\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "\n",
    "    return home_team_win_prob, draw_prob, away_team_win_prob\n",
    "\n",
    "\n",
    "\n",
    "print('##########################')\n",
    "print('Today\\'s matches')\n",
    "\n",
    "predict_match('St Etienne', 'Laval', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Caen', 'Concarneau', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Grenoble', 'Dunkerque', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Paris FC', 'Annecy', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Quevilly Rouen', 'Guingamp', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Rodez', 'Pau FC', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Bastia', 'Angers', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Troyes', 'Ajaccio', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Valenciennes', 'Amiens', catboost_model, df, label_encoder)\n",
    "\n",
    "predict_match('Auxerre', 'Bordeaux', catboost_model, df, label_encoder)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:20:25.443790800Z",
     "start_time": "2024-01-20T06:20:25.259401700Z"
    }
   },
   "id": "d4aaf95550397fc0",
   "execution_count": 643
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the imputer (you can change the strategy to 'median' or 'most_frequent' if more appropriate)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Fit on the training data and transform both training and testing data\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:45:08.010254900Z",
     "start_time": "2024-01-20T05:45:07.979701900Z"
    }
   },
   "id": "5afcd0ee014014b1",
   "execution_count": 638
  },
  {
   "cell_type": "markdown",
   "source": [
    "## using random forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd674d54c6445cb0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.62      0.71        16\n",
      "           1       0.11      0.25      0.15         4\n",
      "           2       0.76      0.72      0.74        18\n",
      "\n",
      "    accuracy                           0.63        38\n",
      "   macro avg       0.57      0.53      0.54        38\n",
      "weighted avg       0.72      0.63      0.67        38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Then scale the imputed data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "    \n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1_macro')\n",
    "grid_search.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Best Model Evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:46:25.520438300Z",
     "start_time": "2024-01-20T05:45:10.467216Z"
    }
   },
   "id": "561f276f86e12a37",
   "execution_count": 639
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Today's matches\n",
      "Encoded Home Team: 17, Encoded Away Team: 12\n",
      "St Etienne win probability: 0.5175218253968255\n",
      "Laval win probability: 0.2699285714285714\n",
      "Draw probability: 0.21254960317460309\n",
      "Encoded Home Team: 7, Encoded Away Team: 8\n",
      "Caen win probability: 0.28498015873015875\n",
      "Concarneau win probability: 0.44179761904761894\n",
      "Draw probability: 0.2732222222222223\n",
      "Encoded Home Team: 10, Encoded Away Team: 9\n",
      "Grenoble win probability: 0.26754978354978365\n",
      "Dunkerque win probability: 0.3689880952380953\n",
      "Draw probability: 0.36346212121212135\n",
      "Encoded Home Team: 13, Encoded Away Team: 3\n",
      "Paris FC win probability: 0.12079761904761906\n",
      "Annecy win probability: 0.6233869047619047\n",
      "Draw probability: 0.2558154761904762\n",
      "Encoded Home Team: 15, Encoded Away Team: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\dagbo_b40tnyc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quevilly Rouen win probability: 0.3630634920634921\n",
      "Guingamp win probability: 0.38047222222222227\n",
      "Draw probability: 0.2564642857142857\n",
      "Encoded Home Team: 16, Encoded Away Team: 14\n",
      "Rodez win probability: 0.2244107142857143\n",
      "Pau FC win probability: 0.32725793650793655\n",
      "Draw probability: 0.44833134920634926\n",
      "Encoded Home Team: 5, Encoded Away Team: 2\n",
      "Bastia win probability: 0.24737499999999998\n",
      "Angers win probability: 0.24841071428571432\n",
      "Draw probability: 0.5042142857142857\n",
      "Encoded Home Team: 18, Encoded Away Team: 0\n",
      "Troyes win probability: 0.3983869047619047\n",
      "Ajaccio win probability: 0.1853055555555555\n",
      "Draw probability: 0.41630753968253975\n",
      "Encoded Home Team: 19, Encoded Away Team: 1\n",
      "Valenciennes win probability: 0.40711309523809525\n",
      "Amiens win probability: 0.07601984126984125\n",
      "Draw probability: 0.5168670634920635\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.40711309523809525, 0.07601984126984125, 0.5168670634920635)"
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict_match(home_team, away_team, best_model, df, label_encoder,scaler):\n",
    "     # Debugging: Check if the team names are in label_encoder's classes\n",
    "    if home_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Home team name '{home_team}' not recognized.\")\n",
    "    if away_team not in label_encoder.classes_:\n",
    "        raise ValueError(f\"Away team name '{away_team}' not recognized.\")\n",
    "\n",
    "    # Transform team names\n",
    "    home_team_encoded = label_encoder.transform([home_team])[0]\n",
    "    away_team_encoded = label_encoder.transform([away_team])[0]\n",
    "\n",
    "    # Debugging: Print encoded values\n",
    "    print(f\"Encoded Home Team: {home_team_encoded}, Encoded Away Team: {away_team_encoded}\")\n",
    "\n",
    "    # Prepare the match data with relevant features\n",
    "    match_data = {\n",
    "        'HomeTeam_encoded': label_encoder.transform([home_team])[0],\n",
    "        'AwayTeam_encoded': label_encoder.transform([away_team])[0],\n",
    "        'HomeTeamRecentForm': calculate_form_points(home_team, df)[0],\n",
    "        'AwayTeamRecentForm': calculate_form_points(away_team, df)[1],\n",
    "        'HomeTeamAvgGoals': df[df['HomeTeam'] == home_team]['FTHG'].mean(),\n",
    "        'AwayTeamAvgGoals': df[df['AwayTeam'] == away_team]['FTAG'].mean(),\n",
    "        'HomeTeamPoints': df[df['HomeTeam'] == home_team]['FTR_encoded'].sum() / df[df['HomeTeam'] == home_team]['FTR_encoded'].count(),\n",
    "        'AwayTeamPoints': df[df['AwayTeam'] == away_team]['FTR_encoded'].sum() / df[df['AwayTeam'] == away_team]['FTR_encoded'].count(),\n",
    "        'HomeGoalsScoredVariance': df[df['HomeTeam'] == home_team]['FTHG'].var(),\n",
    "        'AwayGoalsScoredVariance': df[df['AwayTeam'] == away_team]['FTAG'].var(),\n",
    "        'HomeGoalsScoredAvg_3': df[df['HomeTeam'] == home_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_3': df[df['AwayTeam'] == away_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_3': df[df['HomeTeam'] == home_team]['FTAG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_3': df[df['AwayTeam'] == away_team]['FTHG'].rolling(3, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsScoredAvg_5': df[df['HomeTeam'] == home_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsScoredAvg_5': df[df['AwayTeam'] == away_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'HomeGoalsConcededAvg_5': df[df['HomeTeam'] == home_team]['FTAG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        'AwayGoalsConcededAvg_5': df[df['AwayTeam'] == away_team]['FTHG'].rolling(5, min_periods=1).mean().iloc[-1],\n",
    "        \n",
    "        # Add other features as required by the model, calculated or retrieved as done during training\n",
    "        # ...\n",
    "    }\n",
    "\n",
    "    match_df = pd.DataFrame([match_data])\n",
    "    match_scaled = scaler.transform(match_df)\n",
    "    # Make predictions\n",
    "    home_team_win_prob = best_model.predict_proba(match_scaled)[0][0]\n",
    "    away_team_win_prob = best_model.predict_proba(match_scaled)[0][2]\n",
    "    draw_prob = best_model.predict_proba(match_scaled)[0][1]\n",
    "    # Print the results\n",
    "    print(f\"{home_team} win probability: {home_team_win_prob}\")\n",
    "    print(f\"{away_team} win probability: {away_team_win_prob}\")\n",
    "    print(f\"Draw probability: {draw_prob}\")\n",
    "    \n",
    "    return home_team_win_prob, away_team_win_prob, draw_prob\n",
    "\n",
    "\n",
    "\n",
    "print('##########################')\n",
    "print('Today\\'s matches')\n",
    "\n",
    "predict_match('St Etienne', 'Laval', best_model, df, label_encoder,scaler)\n",
    "\n",
    "predict_match('Caen', 'Concarneau', best_model, df, label_encoder,scaler)\n",
    "\n",
    "predict_match('Grenoble', 'Dunkerque', best_model, df, label_encoder,scaler)\n",
    "\n",
    "predict_match('Paris FC', 'Annecy', best_model, df, label_encoder,scaler)\n",
    "\n",
    "predict_match('Quevilly Rouen', 'Guingamp', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Rodez', 'Pau FC', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Bastia', 'Angers', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Troyes', 'Ajaccio', best_model, df, label_encoder, scaler)\n",
    "\n",
    "predict_match('Valenciennes', 'Amiens', best_model, df, label_encoder, scaler)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T05:54:06.974194700Z",
     "start_time": "2024-01-20T05:54:06.530294900Z"
    }
   },
   "id": "c6620460d2ef2cd2",
   "execution_count": 641
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d715b9c2999b356c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
